{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from torch import optim\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './GANdata'\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "train_ds = datasets.MNIST(data_path, train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "#for check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some blocks\n",
    "\n",
    "class ResBlock2d(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, stride, use_dropout, use_bias, padding):\n",
    "        super(ResBlock2d, self).__init__()\n",
    "        self.conv_block = []\n",
    "        self.conv_block.append(nn.Conv2d(channels, channels, kernel_size, stride, bias=use_bias, padding=padding))\n",
    "        if use_dropout > 0:\n",
    "            self.conv_block.append(nn.Dropout(use_dropout))\n",
    "        self.conv_block.append(nn.Conv2d(channels, channels, kernel_size, stride, bias=use_bias, padding=padding))\n",
    "        \n",
    "        self.conv_block = nn.Sequential(*self.conv_block)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNorm2d(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, stride, use_dropout=0, padding=0, use_bias=False, norm_type=nn.InstanceNorm2d, activation_type=nn.ReLU, activation_value=True):\n",
    "        super(ResNorm2d, self).__init__()\n",
    "        self.res = ResBlock2d(channels, kernel_size, stride, use_dropout, use_bias, padding)\n",
    "        self.norm = norm_type(channels)\n",
    "        if activation_type != nn.ReLU:\n",
    "            self.activation = activation_type(activation_value, inplace=True)\n",
    "        else:\n",
    "            self.activation = activation_type(activation_value)\n",
    "        \n",
    "        self.model = nn.Sequential(self.res, self.norm, self.activation)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        return self.model(x)\n",
    "        \n",
    "\n",
    "class ConvNorm2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0, use_dropout=0, use_bias=False, norm_type=nn.InstanceNorm2d, activation_type=nn.ReLU, activation_value=True):\n",
    "        super(ConvNorm2d, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride, bias=use_bias, padding=padding)\n",
    "        self.norm = norm_type(out_channels)\n",
    "        if activation_type != nn.ReLU:\n",
    "            self.activation = activation_type(activation_value, inplace=True)\n",
    "        else:\n",
    "            self.activation = activation_type(activation_value)\n",
    "        \n",
    "        self.model = nn.Sequential(self.conv2d, self.norm, self.activation)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        return self.model(x)\n",
    "    \n",
    "\n",
    "class UpConvNorm2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0, output_padding=0, use_dropout=0, use_bias=False, norm_type=nn.InstanceNorm2d, activation_type=nn.ReLU, activation_value=True):\n",
    "        super(UpConvNorm2d, self).__init__()\n",
    "        self.upconv2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, bias=use_bias, padding=padding, output_padding=output_padding)\n",
    "        self.norm = norm_type(out_channels)\n",
    "        if activation_type != nn.ReLU:\n",
    "            self.activation = activation_type(activation_value, inplace=True)\n",
    "        else:\n",
    "            self.activation = activation_type(activation_value)\n",
    "        \n",
    "        self.model = nn.Sequential(self.upconv2d, self.norm, self.activation)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        return self.model(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngf, nc, img_size=(3, 128, 128), norm_type=nn.InstanceNorm2d, use_dropout=0):\n",
    "        super(Generator, self).__init__()\n",
    "        self.img_size = img_size # 1 x 28 x 28 for MNIST\n",
    "        self.ngf = ngf\n",
    "        self.nc = nc\n",
    "        self.use_bias = (norm_type == nn.InstanceNorm2d)\n",
    "        self.norm_type = norm_type\n",
    "        \n",
    "        if img_size[-1] == 128:\n",
    "            self.get_resnet(in_channels=self.img_size[0], down=2, mid=6, use_dropout=use_dropout)\n",
    "        elif img_size[-1] == 256:\n",
    "            self.get_resnet(in_channels=self.img_size[0], down=2, mid=9, use_dropout=use_dropout)\n",
    "        else:\n",
    "            raise AttributeError\n",
    "        \n",
    "\n",
    "    def get_resnet(self, in_channels, down, mid, use_dropout):\n",
    "        self.model = []\n",
    "        out_channels = self.ngf\n",
    "        self.model.append(nn.ReflectionPad2d(3)) # paper\n",
    "        self.model.append(ConvNorm2d(in_channels, out_channels, 7, 1, padding=0, use_dropout=use_dropout, use_bias=self.use_bias, norm_type=self.norm_type))\n",
    "        # downsampling\n",
    "        for i in range(1, down+1):\n",
    "            self.model.append(ConvNorm2d(out_channels, out_channels*2, 3, 2, padding=1, use_dropout=use_dropout, use_bias=self.use_bias, norm_type=self.norm_type))\n",
    "            out_channels *= 2\n",
    "        \n",
    "        # res\n",
    "        for i in range(1, mid+1):\n",
    "            self.model.append(ResNorm2d(out_channels, 3, 1, use_dropout=use_dropout, use_bias=self.use_bias, norm_type=self.norm_type, padding=1))\n",
    "        # TODO - add reflection padding at ResNorm2d\n",
    "        # upsampling\n",
    "        for i in range(1, down+1):\n",
    "            self.model.append(UpConvNorm2d(out_channels, out_channels//2, 3, 2, padding=1, output_padding=1, use_dropout=use_dropout, use_bias=self.use_bias, norm_type=self.norm_type))\n",
    "            out_channels //= 2\n",
    "        \n",
    "        self.model.append(nn.ReflectionPad2d(3)) # paper\n",
    "        self.model.append(nn.Conv2d(out_channels, self.nc, 7, 1, bias=self.use_bias, padding=0))\n",
    "        self.model.append(nn.Tanh())\n",
    "        \n",
    "        self.model = nn.Sequential(*self.model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 134, 134])\n",
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # test generator_resnet\n",
    "    test_generator = Generator(64, 3, (3, 128, 128)).to(device)\n",
    "    test_noise = torch.randn(1, 3, 128, 128).to(device)\n",
    "    output = test_generator(test_noise)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngf, nc, img_size=(3, 128, 128), norm_type=nn.InstanceNorm2d, use_dropout=0):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.ngf = ngf\n",
    "        self.nc = nc\n",
    "        self.use_bias = (norm_type == nn.InstanceNorm2d)\n",
    "        self.norm_type = norm_type\n",
    "        \n",
    "        self.get_model(img_size[0], 4, use_dropout)\n",
    "        \n",
    "    \n",
    "    def get_model(self, in_channels, n, use_dropout):\n",
    "        self.model = []\n",
    "        # self.model.append(nn.Conv2d(in_channels, self.ngf, 4, 2, padding=1))\n",
    "        # self.model.append(nn.LeakyReLU(0.2, True))\n",
    "        #in_channels = self.ngf\n",
    "        out_channels = self.ngf\n",
    "        for _ in range(n-1):\n",
    "            self.model.append(ConvNorm2d(in_channels, out_channels, 4, 2, use_bias=self.use_bias, padding=1, norm_type=self.norm_type, activation_type=nn.LeakyReLU, activation_value=0.2))\n",
    "            in_channels = out_channels\n",
    "            out_channels *= 2\n",
    "        \n",
    "        self.model.append(ConvNorm2d(in_channels, in_channels, 4, 1, use_bias=self.use_bias, padding=1, norm_type=self.norm_type, activation_type=nn.LeakyReLU, activation_value=0.2))\n",
    "        \n",
    "        self.model.append(nn.Conv2d(in_channels, 1, 4, 1, padding=1))\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        output = self.model(img)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 128, 32, 32])\n",
      "torch.Size([1, 256, 16, 16])\n",
      "torch.Size([1, 1, 14, 14])\n",
      "torch.Size([1, 1, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # test discriminator\n",
    "    test_discriminator = Discriminator(64, 3, (3, 128, 128)).to(device)\n",
    "    test_noise = torch.randn(1, 3, 128, 128).to(device)\n",
    "    output = test_discriminator(test_noise)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANCustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path, mode='train', res=128, serial_batches=False):\n",
    "        super(CycleGANCustomDataset, self).__init__()\n",
    "        self.path_A = dataset_path + \"/\" + mode + \"A/\"\n",
    "        self.path_B = dataset_path + \"/\" + mode + \"B/\"\n",
    "        \n",
    "        self.img_list_A = sorted(os.listdir(self.path_A))\n",
    "        self.img_list_B = sorted(os.listdir(self.path_B))\n",
    "        \n",
    "        self.len_A = len(self.img_list_A)\n",
    "        self.len_B = len(self.img_list_B)\n",
    "        self.res = res\n",
    "        self.serial_batches = serial_batches\n",
    "        self.transform = transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                          transforms.Resize(res, transforms.InterpolationMode.BICUBIC),\n",
    "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "    def __len__(self):\n",
    "        return max(self.len_A, self.len_B)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_A = self.transform(Image.open(self.path_A+self.img_list_A[index % self.len_A]).convert('RGB'))\n",
    "        if self.serial_batches:\n",
    "            index_b = index % self.len_B\n",
    "        else:\n",
    "            index_b = int(torch.randint(0, self.len_B - 1, (1,))[0])\n",
    "        img_B = self.transform(Image.open(self.path_B+self.img_list_B[index_b]).convert('RGB'))\n",
    "        #print(img_A, img_B)\n",
    "        return {'A': img_A, 'B': img_B}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    \n",
    "    def __init__(self, generator, discriminator, ngf, ndf, nc, img_size, device, lambda_cyc=10, lambda_id=0.5, gan_loss_type=nn.MSELoss):\n",
    "        \n",
    "        self.ngf = ngf\n",
    "        self.ndf = ndf\n",
    "        self.nc = nc\n",
    "        self.img_size = img_size\n",
    "        self.lambda_cyc = lambda_cyc\n",
    "        self.lambda_id = lambda_id\n",
    "        self.G_A = generator(ngf, nc, img_size, use_dropout = 0.5).to(device)\n",
    "        self.G_B = generator(ngf, nc, img_size, use_dropout = 0.5).to(device)\n",
    "        self.D_A = discriminator(ndf, nc, img_size).to(device)\n",
    "        self.D_B = discriminator(ndf, nc, img_size).to(device)\n",
    "        self.gan_loss_type = gan_loss_type\n",
    "        \n",
    "        self.initialize_network(init_type='normal', init_gain=0.02)\n",
    "    \n",
    "    def loss_GAN(self, prediction, target):\n",
    "        return self.gan_loss_type()(prediction, target)\n",
    "    \n",
    "    def loss_cycle(self, f_g_x, x, g_f_y, y):\n",
    "        return nn.L1Loss()(f_g_x, x) + nn.L1Loss()(g_f_y, y)\n",
    "    \n",
    "    def loss_id(self, g_y, y, f_x, x):\n",
    "        return nn.L1Loss()(g_y, y) + nn.L1Loss()(f_x, x)\n",
    "    \n",
    "    def set_optimizer(self, lr, beta1):\n",
    "        self.opt_G = optim.Adam(itertools.chain(self.G_A.parameters(), self.G_B.parameters()), lr=lr, betas=(beta1, 0.999))\n",
    "        self.opt_D = optim.Adam(itertools.chain(self.D_A.parameters(), self.D_B.parameters()), lr=lr, betas=(beta1, 0.999))\n",
    "    \n",
    "    \n",
    "    def get_scheduler(self, optimizer, num_epochs, lr_args):\n",
    "        lr_policy = lr_args['lr_policy']\n",
    "        if lr_policy == 'linear':\n",
    "            def lambda_rule(epoch):\n",
    "                lr_l = 1.0 - max(0, epoch + lr_args['epoch_count'] - num_epochs) / float(lr_args['n_epochs_decay'] + 1) # start epoch는 1로?\n",
    "                return lr_l\n",
    "            scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "        elif lr_policy == 'step':\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_args['lr_decay_iters'], gamma=0.1)\n",
    "        elif lr_policy == 'plateau':\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "        elif lr_policy == 'cosine':\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)\n",
    "        else:\n",
    "            return NotImplementedError('learning rate policy [%s] is not implemented', lr_args['lr_policy'])\n",
    "\n",
    "        return scheduler\n",
    "    \n",
    "    def initialize_network(self, init_type='normal', init_gain=0.02):\n",
    "        \n",
    "        def initialize_model(model):\n",
    "            classname = model.__class__.__name__\n",
    "            \n",
    "            if hasattr(model, 'weight') and classname.find('Conv') != -1 or classname.find('Linear') != -1:\n",
    "                if init_type == 'normal':\n",
    "                    nn.init.normal_(model.weight.data, 0.0, init_gain)\n",
    "                elif init_type == 'xavier':\n",
    "                    nn.init.xavier_normal_(model.weight.data, gain=init_gain)\n",
    "                elif init_type == 'kaiming':\n",
    "                    nn.init.kaiming_normal_(model.weight.data, a=0, mode='fan_in')\n",
    "                elif init_type == 'orthogonal':\n",
    "                    nn.init.orthogonal_(model.weight.data, gain=init_gain)\n",
    "                else:\n",
    "                    raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "                if hasattr(model, 'bias') and model.bias is not None:\n",
    "                    nn.init.constant_(model.bias.data, 0)\n",
    "            # batchnorm\n",
    "            elif classname.find('BatchNorm') != -1: # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "                nn.init.normal_(model.weight.data, 1.0, gain=init_gain)\n",
    "                nn.init.constant_(model.bias.data, 0)\n",
    "        \n",
    "        self.D_A.apply(initialize_model)\n",
    "        self.D_B.apply(initialize_model)\n",
    "        self.G_A.apply(initialize_model)\n",
    "        self.G_B.apply(initialize_model)\n",
    "    \n",
    "    \n",
    "    def train(self, dataloader, num_epochs, lr_args):\n",
    "        # log 관련\n",
    "        log_dict = {'loss_G': [], 'loss_D': []}\n",
    "        cnt = 0\n",
    "        \n",
    "        self.set_optimizer(lr_args['lr'], 0.5)\n",
    "        scheduler_D = self.get_scheduler(self.opt_D, num_epochs, lr_args)\n",
    "        scheduler_G = self.get_scheduler(self.opt_G, num_epochs, lr_args)\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, data in enumerate(dataloader):\n",
    "                # TODO : dataloader에 collate 작성해서 A, B를 따로 빼 올 수 있도록 하기\n",
    "                #print(i, data)\n",
    "                x_batch_A = data['A'].to(device)\n",
    "                x_batch_B = data['B'].to(device)\n",
    "\n",
    "                # G\n",
    "                self.opt_G.zero_grad()\n",
    "                self.opt_D.zero_grad()\n",
    "                for param in self.D_A.parameters():\n",
    "                    param.requires_grad=False\n",
    "                for param in self.D_B.parameters():\n",
    "                    param.requires_grad=False\n",
    "\n",
    "                G_A_output = self.G_A(x_batch_A) # fake B\n",
    "                D_B_G_A_output = self.D_B(G_A_output) # discriminate fake B\n",
    "                B_G_A_output = self.G_B(G_A_output) # reconstructed A\n",
    "                G_B_output = self.G_B(x_batch_B) # fake A\n",
    "                D_A_G_B_output = self.D_A(G_B_output) # discriminate fake A\n",
    "                A_G_B_output = self.G_A(G_B_output) # reconstructed B\n",
    "                \n",
    "                real_y = torch.ones_like(D_B_G_A_output).to(device)\n",
    "                fake_y = torch.ones_like(D_B_G_A_output).to(device)\n",
    "                \n",
    "                g1 = self.loss_GAN(D_B_G_A_output, real_y.detach())\n",
    "                g2 = self.loss_GAN(D_A_G_B_output, real_y.detach())\n",
    "                loss_GAN = g1 + g2\n",
    "                loss_cycle = self.lambda_cyc * self.loss_cycle(B_G_A_output, x_batch_A, A_G_B_output, x_batch_B)\n",
    "                loss_id = self.lambda_id * self.loss_id(G_A_output, x_batch_A, G_B_output, x_batch_B)\n",
    "                loss_G = loss_GAN + loss_cycle + loss_id\n",
    "                \n",
    "                loss_G.backward()\n",
    "                self.opt_G.step()\n",
    "                \n",
    "                # D\n",
    "                for param in self.D_A.parameters():\n",
    "                    param.requires_grad=True\n",
    "                for param in self.D_B.parameters():\n",
    "                    param.requires_grad=True\n",
    "                \n",
    "                \n",
    "                loss_GAN_D_A = (self.loss_GAN(self.D_A(x_batch_A), real_y) + self.loss_GAN(self.D_A(G_B_output.detach()), fake_y)) / 2\n",
    "                loss_GAN_D_A.backward()\n",
    "                loss_GAN_D_B = (self.loss_GAN(self.D_B(x_batch_B), real_y) + self.loss_GAN(self.D_B(G_A_output.detach()), fake_y)) / 2 # grad true인 상태에서!\n",
    "                loss_GAN_D_B.backward()\n",
    "                \n",
    "                self.opt_D.step()\n",
    "                \n",
    "                \n",
    "                # TODO - logging\n",
    "                \n",
    "                if cnt % 100 == 0:\n",
    "                    log_dict['loss_G'].append(loss_G.item())\n",
    "                    log_dict['loss_D'].append(loss_GAN_D_A.item() + loss_GAN_D_B.item())\n",
    "                    print(f'epoch {epoch}, loss_GAN {g1.item()} {g2.item()}, loss_cycle {loss_cycle.item()}, loss_id {loss_id.item()}, loss_D {loss_GAN_D_A.item() + loss_GAN_D_B.item()}')\n",
    "                \n",
    "            scheduler_D.step()\n",
    "            scheduler_G.step()\n",
    "\n",
    "        \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096 1096\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "\n",
    "train_dataset = CycleGANCustomDataset(\"../data/maps\", 'train', 256, False)\n",
    "print(train_dataset.len_A, train_dataset.len_B)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CycleGAN(Generator, Discriminator, 64, 64, 3, (3, 256, 256), lambda_cyc=10, lambda_id=0.5, gan_loss_type=nn.MSELoss, device=device)\n",
    "lr_args = {'lr': 0.0002, 'lr_policy': 'linear', 'lr_decay_iters': 50, 'epoch_count': 1, 'n_epochs': 100, 'n_epochs_decay': 100} # 100 epoch동안 그대로, 100 epoch 동안 decay\n",
    "\n",
    "model.train(train_dataloader, 201, lr_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.G_B.state_dict(), \"CycleGAN/models/cyclegan_generator_A.pt\")\n",
    "torch.save(model.D_B.state_dict(), \"CycleGAN/models/cyclegan_discriminator_A.pt\")\n",
    "torch.save(model.G_B.state_dict(), \"CycleGAN/models/cyclegan_generator_B.pt\")\n",
    "torch.save(model.D_B.state_dict(), \"CycleGAN/models/cyclegan_discriminator_B.pt\")                   \n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
