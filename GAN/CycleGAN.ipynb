{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from torch import optim\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './GANdata'\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "train_ds = datasets.MNIST(data_path, train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "#for check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some blocks\n",
    "\n",
    "class ResBlock2d(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, stride, use_dropout, use_bias, padding):\n",
    "        super(ResBlock2d, self).__init__()\n",
    "        self.conv_block = []\n",
    "        self.conv_block.append(nn.Conv2d(channels, channels, kernel_size, stride, bias=use_bias, padding=padding))\n",
    "        if use_dropout > 0:\n",
    "            self.conv_block.append(nn.Dropout(use_dropout))\n",
    "        self.conv_block.append(nn.Conv2d(channels, channels, kernel_size, stride, bias=use_bias, padding=padding))\n",
    "        \n",
    "        self.conv_block = nn.Sequential(*self.conv_block)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNorm2d(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, stride, use_dropout=0, padding=0, use_bias=False, norm_type=nn.InstanceNorm2d, activation_type=nn.ReLU, activation_value=True):\n",
    "        super(ResNorm2d, self).__init__()\n",
    "        self.res = ResBlock2d(channels, kernel_size, stride, use_dropout, use_bias, padding)\n",
    "        self.norm = norm_type(channels)\n",
    "        if activation_type != nn.ReLU:\n",
    "            self.activation = activation_type(activation_value, inplace=True)\n",
    "        else:\n",
    "            self.activation = activation_type(activation_value)\n",
    "        \n",
    "        self.model = nn.Sequential(self.res, self.norm, self.activation)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        return self.model(x)\n",
    "        \n",
    "\n",
    "class ConvNorm2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0, use_dropout=0, use_bias=False, norm_type=nn.InstanceNorm2d, activation_type=nn.ReLU, activation_value=True):\n",
    "        super(ConvNorm2d, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size, stride, bias=use_bias, padding=padding)\n",
    "        self.norm = norm_type(out_channels)\n",
    "        if activation_type != nn.ReLU:\n",
    "            self.activation = activation_type(activation_value, inplace=True)\n",
    "        else:\n",
    "            self.activation = activation_type(activation_value)\n",
    "        \n",
    "        self.model = nn.Sequential(self.conv2d, self.norm, self.activation)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        return self.model(x)\n",
    "    \n",
    "\n",
    "class UpConvNorm2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0, output_padding=0, use_dropout=0, use_bias=False, norm_type=nn.InstanceNorm2d, activation_type=nn.ReLU, activation_value=True):\n",
    "        super(UpConvNorm2d, self).__init__()\n",
    "        self.upconv2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, bias=use_bias, padding=padding, output_padding=output_padding)\n",
    "        self.norm = norm_type(out_channels)\n",
    "        if activation_type != nn.ReLU:\n",
    "            self.activation = activation_type(activation_value, inplace=True)\n",
    "        else:\n",
    "            self.activation = activation_type(activation_value)\n",
    "        \n",
    "        self.model = nn.Sequential(self.upconv2d, self.norm, self.activation)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        return self.model(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngf, nc, img_size=(3, 128, 128), norm_type=nn.InstanceNorm2d, use_dropout=0):\n",
    "        super(Generator, self).__init__()\n",
    "        self.img_size = img_size # 1 x 28 x 28 for MNIST\n",
    "        self.ngf = ngf\n",
    "        self.nc = nc\n",
    "        self.use_bias = (norm_type == nn.InstanceNorm2d)\n",
    "        self.norm_type = norm_type\n",
    "        \n",
    "        if img_size[-1] == 128:\n",
    "            self.get_resnet(in_channels=self.img_size[0], down=2, mid=6, use_dropout=use_dropout)\n",
    "        elif img_size[-1] == 256:\n",
    "            self.get_resnet(in_channels=self.img_size[0], down=2, mid=9, use_dropout=use_dropout)\n",
    "        else:\n",
    "            raise AttributeError\n",
    "        \n",
    "\n",
    "    def get_resnet(self, in_channels, down, mid, use_dropout):\n",
    "        self.model = []\n",
    "        out_channels = self.ngf\n",
    "        self.model.append(nn.ReflectionPad2d(3)) # paper\n",
    "        self.model.append(ConvNorm2d(in_channels, out_channels, 7, 1, padding=0, use_dropout=use_dropout, use_bias=self.use_bias, norm_type=self.norm_type))\n",
    "        # downsampling\n",
    "        for i in range(1, down+1):\n",
    "            self.model.append(ConvNorm2d(out_channels, out_channels*2, 3, 2, padding=1, use_dropout=use_dropout, use_bias=self.use_bias, norm_type=self.norm_type))\n",
    "            out_channels *= 2\n",
    "        \n",
    "        # res\n",
    "        for i in range(1, mid+1):\n",
    "            self.model.append(ResNorm2d(out_channels, 3, 1, use_dropout=use_dropout, use_bias=self.use_bias, norm_type=self.norm_type, padding=1))\n",
    "        # TODO - add reflection padding at ResNorm2d\n",
    "        # upsampling\n",
    "        for i in range(1, down+1):\n",
    "            self.model.append(UpConvNorm2d(out_channels, out_channels//2, 3, 2, padding=1, output_padding=1, use_dropout=use_dropout, use_bias=self.use_bias, norm_type=self.norm_type))\n",
    "            out_channels //= 2\n",
    "        \n",
    "        self.model.append(nn.ReflectionPad2d(3)) # paper\n",
    "        self.model.append(nn.Conv2d(out_channels, self.nc, 7, 1, bias=self.use_bias, padding=0))\n",
    "        self.model.append(nn.Tanh())\n",
    "        \n",
    "        self.model = nn.Sequential(*self.model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 134, 134])\n",
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # test generator_resnet\n",
    "    test_generator = Generator(64, 3, (3, 128, 128)).to(device)\n",
    "    test_noise = torch.randn(1, 3, 128, 128).to(device)\n",
    "    output = test_generator(test_noise)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngf, nc, img_size=(3, 128, 128), norm_type=nn.InstanceNorm2d, use_dropout=0):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.ngf = ngf\n",
    "        self.nc = nc\n",
    "        self.use_bias = (norm_type == nn.InstanceNorm2d)\n",
    "        self.norm_type = norm_type\n",
    "        \n",
    "        self.get_model(img_size[0], 4, use_dropout)\n",
    "        \n",
    "    \n",
    "    def get_model(self, in_channels, n, use_dropout):\n",
    "        self.model = []\n",
    "        # self.model.append(nn.Conv2d(in_channels, self.ngf, 4, 2, padding=1))\n",
    "        # self.model.append(nn.LeakyReLU(0.2, True))\n",
    "        #in_channels = self.ngf\n",
    "        out_channels = self.ngf\n",
    "        for _ in range(n-1):\n",
    "            self.model.append(ConvNorm2d(in_channels, out_channels, 4, 2, use_bias=self.use_bias, padding=1, norm_type=self.norm_type, activation_type=nn.LeakyReLU, activation_value=0.2))\n",
    "            in_channels = out_channels\n",
    "            out_channels *= 2\n",
    "        \n",
    "        self.model.append(ConvNorm2d(in_channels, in_channels, 4, 1, use_bias=self.use_bias, padding=1, norm_type=self.norm_type, activation_type=nn.LeakyReLU, activation_value=0.2))\n",
    "        \n",
    "        self.model.append(nn.Conv2d(in_channels, 1, 4, 1, padding=1))\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        output = self.model(img)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 128, 32, 32])\n",
      "torch.Size([1, 256, 16, 16])\n",
      "torch.Size([1, 1, 14, 14])\n",
      "torch.Size([1, 1, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # test discriminator\n",
    "    test_discriminator = Discriminator(64, 3, (3, 128, 128)).to(device)\n",
    "    test_noise = torch.randn(1, 3, 128, 128).to(device)\n",
    "    output = test_discriminator(test_noise)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANCustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path, mode='train', res=128, serial_batches=False):\n",
    "        super(CycleGANCustomDataset, self).__init__()\n",
    "        self.path_A = dataset_path + \"/\" + mode + \"A/\"\n",
    "        self.path_B = dataset_path + \"/\" + mode + \"B/\"\n",
    "        \n",
    "        self.img_list_A = sorted(os.listdir(self.path_A))\n",
    "        self.img_list_B = sorted(os.listdir(self.path_B))\n",
    "        \n",
    "        self.len_A = len(self.img_list_A)\n",
    "        self.len_B = len(self.img_list_B)\n",
    "        self.res = res\n",
    "        self.serial_batches = serial_batches\n",
    "        self.transform = transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                          transforms.Resize(res, transforms.InterpolationMode.BICUBIC),\n",
    "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "    def __len__(self):\n",
    "        return max(self.len_A, self.len_B)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_A = self.transform(Image.open(self.path_A+self.img_list_A[index % self.len_A]).convert('RGB'))\n",
    "        if self.serial_batches:\n",
    "            index_b = index % self.len_B\n",
    "        else:\n",
    "            index_b = int(torch.randint(0, self.len_B - 1, (1,))[0])\n",
    "        img_B = self.transform(Image.open(self.path_B+self.img_list_B[index_b]).convert('RGB'))\n",
    "        #print(img_A, img_B)\n",
    "        return {'A': img_A, 'B': img_B}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    \n",
    "    def __init__(self, generator, discriminator, ngf, ndf, nc, img_size, device, lambda_cyc=10, lambda_id=0.5, gan_loss_type=nn.MSELoss):\n",
    "        \n",
    "        self.ngf = ngf\n",
    "        self.ndf = ndf\n",
    "        self.nc = nc\n",
    "        self.img_size = img_size\n",
    "        self.lambda_cyc = lambda_cyc\n",
    "        self.lambda_id = lambda_id\n",
    "        self.G_A = generator(ngf, nc, img_size, use_dropout = 0.5).to(device)\n",
    "        self.G_B = generator(ngf, nc, img_size, use_dropout = 0.5).to(device)\n",
    "        self.D_A = discriminator(ndf, nc, img_size).to(device)\n",
    "        self.D_B = discriminator(ndf, nc, img_size).to(device)\n",
    "        self.gan_loss_type = gan_loss_type\n",
    "        \n",
    "        self.initialize_network(init_type='normal', init_gain=0.02)\n",
    "    \n",
    "    def loss_GAN(self, prediction, target):\n",
    "        return self.gan_loss_type()(prediction, target)\n",
    "    \n",
    "    def loss_cycle(self, f_g_x, x, g_f_y, y):\n",
    "        return nn.L1Loss()(f_g_x, x) + nn.L1Loss()(g_f_y, y)\n",
    "    \n",
    "    def loss_id(self, g_y, y, f_x, x):\n",
    "        return nn.L1Loss()(g_y, y) + nn.L1Loss()(f_x, x)\n",
    "    \n",
    "    def set_optimizer(self, lr, beta1):\n",
    "        self.opt_G = optim.Adam(itertools.chain(self.G_A.parameters(), self.G_B.parameters()), lr=lr, betas=(beta1, 0.999))\n",
    "        self.opt_D = optim.Adam(itertools.chain(self.D_A.parameters(), self.D_B.parameters()), lr=lr, betas=(beta1, 0.999))\n",
    "    \n",
    "    \n",
    "    def get_scheduler(self, optimizer, num_epochs, lr_args):\n",
    "        lr_policy = lr_args['lr_policy']\n",
    "        if lr_policy == 'linear':\n",
    "            def lambda_rule(epoch):\n",
    "                lr_l = 1.0 - max(0, epoch + lr_args['epoch_count'] - num_epochs) / float(lr_args['n_epochs_decay'] + 1) # start epoch는 1로?\n",
    "                return lr_l\n",
    "            scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "        elif lr_policy == 'step':\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_args['lr_decay_iters'], gamma=0.1)\n",
    "        elif lr_policy == 'plateau':\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "        elif lr_policy == 'cosine':\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)\n",
    "        else:\n",
    "            return NotImplementedError('learning rate policy [%s] is not implemented', lr_args['lr_policy'])\n",
    "\n",
    "        return scheduler\n",
    "    \n",
    "    def initialize_network(self, init_type='normal', init_gain=0.02):\n",
    "        \n",
    "        def initialize_model(model):\n",
    "            classname = model.__class__.__name__\n",
    "            \n",
    "            if hasattr(model, 'weight') and classname.find('Conv') != -1 or classname.find('Linear') != -1:\n",
    "                if init_type == 'normal':\n",
    "                    nn.init.normal_(model.weight.data, 0.0, init_gain)\n",
    "                elif init_type == 'xavier':\n",
    "                    nn.init.xavier_normal_(model.weight.data, gain=init_gain)\n",
    "                elif init_type == 'kaiming':\n",
    "                    nn.init.kaiming_normal_(model.weight.data, a=0, mode='fan_in')\n",
    "                elif init_type == 'orthogonal':\n",
    "                    nn.init.orthogonal_(model.weight.data, gain=init_gain)\n",
    "                else:\n",
    "                    raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "                if hasattr(model, 'bias') and model.bias is not None:\n",
    "                    nn.init.constant_(model.bias.data, 0)\n",
    "            # batchnorm\n",
    "            elif classname.find('BatchNorm') != -1: # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "                nn.init.normal_(model.weight.data, 1.0, gain=init_gain)\n",
    "                nn.init.constant_(model.bias.data, 0)\n",
    "        \n",
    "        self.D_A.apply(initialize_model)\n",
    "        self.D_B.apply(initialize_model)\n",
    "        self.G_A.apply(initialize_model)\n",
    "        self.G_B.apply(initialize_model)\n",
    "    \n",
    "    \n",
    "    def train(self, dataloader, num_epochs, lr_args):\n",
    "        # log 관련\n",
    "        log_dict = {'loss_G': [], 'loss_D': []}\n",
    "        cnt = 0\n",
    "        \n",
    "        self.set_optimizer(lr_args['lr'], 0.5)\n",
    "        scheduler_D = self.get_scheduler(self.opt_D, num_epochs, lr_args)\n",
    "        scheduler_G = self.get_scheduler(self.opt_G, num_epochs, lr_args)\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, data in enumerate(dataloader):\n",
    "                # TODO : dataloader에 collate 작성해서 A, B를 따로 빼 올 수 있도록 하기\n",
    "                #print(i, data)\n",
    "                x_batch_A = data['A'].to(device)\n",
    "                x_batch_B = data['B'].to(device)\n",
    "\n",
    "                # G\n",
    "                self.opt_G.zero_grad()\n",
    "                for param in self.D_A.parameters():\n",
    "                    param.requires_grad=False\n",
    "                for param in self.D_B.parameters():\n",
    "                    param.requires_grad=False\n",
    "\n",
    "                G_A_output = self.G_A(x_batch_A) # fake B\n",
    "                D_B_G_A_output = self.D_B(G_A_output) # discriminate fake B\n",
    "                B_G_A_output = self.G_B(G_A_output) # reconstructed A\n",
    "                G_B_output = self.G_B(x_batch_B) # fake A\n",
    "                D_A_G_B_output = self.D_A(G_B_output) # discriminate fake A\n",
    "                A_G_B_output = self.G_A(G_B_output) # reconstructed B\n",
    "                \n",
    "                real_y = torch.ones_like(D_B_G_A_output).to(device)\n",
    "                fake_y = torch.ones_like(D_B_G_A_output).to(device)\n",
    "                \n",
    "                g1 = self.loss_GAN(D_B_G_A_output, real_y.detach())\n",
    "                g2 = self.loss_GAN(D_A_G_B_output, real_y.detach())\n",
    "                loss_GAN = g1 + g2\n",
    "                loss_cycle = self.lambda_cyc * self.loss_cycle(B_G_A_output, x_batch_A, A_G_B_output, x_batch_B)\n",
    "                loss_id = self.lambda_id * self.loss_id(G_A_output, x_batch_A, G_B_output, x_batch_B)\n",
    "                loss_G = loss_GAN + loss_cycle + loss_id\n",
    "                \n",
    "                loss_G.backward()\n",
    "                self.opt_G.step()\n",
    "                \n",
    "                # D\n",
    "                for param in self.D_A.parameters():\n",
    "                    param.requires_grad=True\n",
    "                for param in self.D_B.parameters():\n",
    "                    param.requires_grad=True\n",
    "                self.opt_D.zero_grad()\n",
    "                \n",
    "                loss_GAN_D_A = (self.loss_GAN(self.D_A(x_batch_A), real_y) + self.loss_GAN(self.D_A(G_B_output.detach()), fake_y)) / 2\n",
    "                loss_GAN_D_A.backward()\n",
    "                loss_GAN_D_B = (self.loss_GAN(self.D_B(x_batch_B), real_y) + self.loss_GAN(self.D_B(G_A_output.detach()), fake_y)) / 2 # grad true인 상태에서!\n",
    "                loss_GAN_D_B.backward()\n",
    "                \n",
    "                self.opt_D.step()\n",
    "                \n",
    "                \n",
    "                # TODO - logging\n",
    "                \n",
    "                if cnt % 100 == 0:\n",
    "                    log_dict['loss_G'].append(loss_G.item())\n",
    "                    log_dict['loss_D'].append(loss_GAN_D_A.item() + loss_GAN_D_B.item())\n",
    "                    print(f'epoch {epoch}, loss_GAN {g1.item()} {g2.item()}, loss_cycle {loss_cycle.item()}, loss_id {loss_id.item()}, loss_D {loss_GAN_D_A.item() + loss_GAN_D_B.item()}')\n",
    "                \n",
    "            scheduler_D.step()\n",
    "            scheduler_G.step()\n",
    "\n",
    "        \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1067 1334\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "\n",
    "train_dataset = CycleGANCustomDataset(\"../data/horse2zebra\", 'train', 256, False)\n",
    "print(train_dataset.len_A, train_dataset.len_B)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss_GAN 2.332944869995117 1.560227394104004, loss_cycle 12.340079307556152, loss_id 0.6127884387969971, loss_D 3.900567054748535\n",
      "epoch 0, loss_GAN 1.5146929025650024 1.7724100351333618, loss_cycle 11.44099235534668, loss_id 0.5829989314079285, loss_D 4.6047362089157104\n",
      "epoch 0, loss_GAN 1.4609966278076172 2.094154119491577, loss_cycle 7.5310845375061035, loss_id 0.38492700457572937, loss_D 3.341578245162964\n",
      "epoch 0, loss_GAN 4.2529473304748535 1.5681021213531494, loss_cycle 9.438218116760254, loss_id 0.43611228466033936, loss_D 4.894220352172852\n",
      "epoch 0, loss_GAN 1.930830717086792 2.03420352935791, loss_cycle 12.00233268737793, loss_id 0.6652095317840576, loss_D 3.2790690660476685\n",
      "epoch 0, loss_GAN 0.6401411890983582 0.6383567452430725, loss_cycle 9.431482315063477, loss_id 0.454633504152298, loss_D 1.5436316132545471\n",
      "epoch 0, loss_GAN 0.555518627166748 0.7321885228157043, loss_cycle 8.882475852966309, loss_id 0.4961792528629303, loss_D 1.6350966691970825\n",
      "epoch 0, loss_GAN 0.4849343001842499 0.4694879353046417, loss_cycle 8.256550788879395, loss_id 0.490489661693573, loss_D 1.0054643750190735\n",
      "epoch 0, loss_GAN 0.41714540123939514 0.4179334044456482, loss_cycle 8.552075386047363, loss_id 0.47104766964912415, loss_D 0.8665757775306702\n",
      "epoch 0, loss_GAN 0.4097006022930145 0.31222179532051086, loss_cycle 9.119853973388672, loss_id 0.47076427936553955, loss_D 0.8916156888008118\n",
      "epoch 0, loss_GAN 0.44105660915374756 0.3229447305202484, loss_cycle 8.412117004394531, loss_id 0.5142960548400879, loss_D 0.7862813472747803\n",
      "epoch 0, loss_GAN 0.3639179468154907 0.37229010462760925, loss_cycle 10.964672088623047, loss_id 0.5655828714370728, loss_D 0.7213326990604401\n",
      "epoch 0, loss_GAN 0.32732319831848145 0.33239591121673584, loss_cycle 8.694841384887695, loss_id 0.46042177081108093, loss_D 0.6779984533786774\n",
      "epoch 0, loss_GAN 0.387383371591568 0.29529181122779846, loss_cycle 9.908141136169434, loss_id 0.4946129620075226, loss_D 0.6821056306362152\n",
      "epoch 0, loss_GAN 0.3087921142578125 0.3166459798812866, loss_cycle 10.508321762084961, loss_id 0.49329274892807007, loss_D 0.6816164553165436\n",
      "epoch 0, loss_GAN 0.3031722903251648 0.2634649872779846, loss_cycle 8.720612525939941, loss_id 0.5364603400230408, loss_D 0.5930845737457275\n",
      "epoch 0, loss_GAN 0.21707913279533386 0.2297976166009903, loss_cycle 11.816707611083984, loss_id 0.5719332695007324, loss_D 0.5426301658153534\n",
      "epoch 0, loss_GAN 0.2589501142501831 0.2985582649707794, loss_cycle 9.889039039611816, loss_id 0.45602649450302124, loss_D 0.6014457046985626\n",
      "epoch 0, loss_GAN 0.21718119084835052 0.2721150815486908, loss_cycle 9.868331909179688, loss_id 0.4762839078903198, loss_D 0.521790474653244\n",
      "epoch 0, loss_GAN 0.2281140238046646 0.20486018061637878, loss_cycle 9.462313652038574, loss_id 0.4984223544597626, loss_D 0.47374531626701355\n",
      "epoch 0, loss_GAN 0.21946364641189575 0.23092366755008698, loss_cycle 8.710164070129395, loss_id 0.4450218677520752, loss_D 0.4770566076040268\n",
      "epoch 0, loss_GAN 0.20176996290683746 0.2212958186864853, loss_cycle 8.241249084472656, loss_id 0.4236356317996979, loss_D 0.4425261616706848\n",
      "epoch 0, loss_GAN 0.21000756323337555 0.20484331250190735, loss_cycle 9.095433235168457, loss_id 0.4801853895187378, loss_D 0.479916051030159\n",
      "epoch 0, loss_GAN 0.17737098038196564 0.23656778037548065, loss_cycle 10.117125511169434, loss_id 0.518751323223114, loss_D 0.4719797670841217\n",
      "epoch 0, loss_GAN 0.17765215039253235 0.2160317748785019, loss_cycle 9.113443374633789, loss_id 0.5008078813552856, loss_D 0.4576089680194855\n",
      "epoch 0, loss_GAN 0.1322549283504486 0.19767354428768158, loss_cycle 7.347434997558594, loss_id 0.31995707750320435, loss_D 0.36417239904403687\n",
      "epoch 0, loss_GAN 0.1354442685842514 0.23372241854667664, loss_cycle 6.64369010925293, loss_id 0.3327609896659851, loss_D 0.411978617310524\n",
      "epoch 0, loss_GAN 0.12258249521255493 0.24282830953598022, loss_cycle 10.488785743713379, loss_id 0.5253591537475586, loss_D 0.4055112153291702\n",
      "epoch 0, loss_GAN 0.112158864736557 0.25700458884239197, loss_cycle 9.849506378173828, loss_id 0.5070326924324036, loss_D 0.44106215238571167\n",
      "epoch 0, loss_GAN 0.11768946796655655 0.41519102454185486, loss_cycle 9.571859359741211, loss_id 0.47626087069511414, loss_D 0.6782656461000443\n",
      "epoch 0, loss_GAN 0.1380489021539688 0.44299012422561646, loss_cycle 9.098987579345703, loss_id 0.4056139886379242, loss_D 0.5565849244594574\n",
      "epoch 0, loss_GAN 0.1811051070690155 0.19227705895900726, loss_cycle 7.46146297454834, loss_id 0.39693576097488403, loss_D 0.48815952241420746\n",
      "epoch 0, loss_GAN 0.18843863904476166 0.1743856966495514, loss_cycle 7.451464653015137, loss_id 0.3637462854385376, loss_D 0.46271854639053345\n",
      "epoch 0, loss_GAN 0.11518806219100952 0.13069544732570648, loss_cycle 6.019356727600098, loss_id 0.38062575459480286, loss_D 0.3934953510761261\n",
      "epoch 0, loss_GAN 0.11650830507278442 0.13343805074691772, loss_cycle 8.456984519958496, loss_id 0.4405217170715332, loss_D 0.33735889196395874\n",
      "epoch 0, loss_GAN 0.12532708048820496 0.12463962286710739, loss_cycle 8.624415397644043, loss_id 0.43396931886672974, loss_D 0.39290687441825867\n",
      "epoch 0, loss_GAN 0.0697588324546814 0.11520259827375412, loss_cycle 9.715812683105469, loss_id 0.5036059617996216, loss_D 0.32237814366817474\n",
      "epoch 0, loss_GAN 0.11826429516077042 0.10459201782941818, loss_cycle 5.525119304656982, loss_id 0.36736807227134705, loss_D 0.36026036739349365\n",
      "epoch 0, loss_GAN 0.2044602483510971 0.10442015528678894, loss_cycle 6.2745771408081055, loss_id 0.31832170486450195, loss_D 0.4288831800222397\n",
      "epoch 0, loss_GAN 0.10832733660936356 0.1516825556755066, loss_cycle 8.489683151245117, loss_id 0.41122785210609436, loss_D 0.3893580436706543\n",
      "epoch 0, loss_GAN 0.12050724029541016 0.1096854880452156, loss_cycle 8.668989181518555, loss_id 0.4949289560317993, loss_D 0.28970861434936523\n",
      "epoch 0, loss_GAN 0.06354320049285889 0.11413441598415375, loss_cycle 9.769475936889648, loss_id 0.502876341342926, loss_D 0.27734772861003876\n",
      "epoch 0, loss_GAN 0.12264787405729294 0.11283471435308456, loss_cycle 14.407464981079102, loss_id 0.7082085609436035, loss_D 0.2274826392531395\n",
      "epoch 0, loss_GAN 0.07461017370223999 0.09722013771533966, loss_cycle 8.186663627624512, loss_id 0.3938995897769928, loss_D 0.24172207713127136\n",
      "epoch 0, loss_GAN 0.06391414254903793 0.07249603420495987, loss_cycle 8.059876441955566, loss_id 0.4232202470302582, loss_D 0.22959089279174805\n",
      "epoch 0, loss_GAN 0.06007898226380348 0.06609564274549484, loss_cycle 7.8200602531433105, loss_id 0.41696929931640625, loss_D 0.1748877614736557\n",
      "epoch 0, loss_GAN 0.05892534926533699 0.06149499863386154, loss_cycle 7.561924457550049, loss_id 0.365836501121521, loss_D 0.200742207467556\n",
      "epoch 0, loss_GAN 0.05114557594060898 0.08773422241210938, loss_cycle 7.522127628326416, loss_id 0.4374150335788727, loss_D 0.16448457539081573\n",
      "epoch 0, loss_GAN 0.05372369661927223 0.0805114284157753, loss_cycle 10.094796180725098, loss_id 0.5605979561805725, loss_D 0.21656493097543716\n",
      "epoch 0, loss_GAN 0.05072939395904541 0.07585412263870239, loss_cycle 6.990056991577148, loss_id 0.2979838252067566, loss_D 0.19665876775979996\n",
      "epoch 0, loss_GAN 0.04170423001050949 0.06092239171266556, loss_cycle 9.75821304321289, loss_id 0.41545820236206055, loss_D 0.19069528579711914\n",
      "epoch 0, loss_GAN 0.0575052835047245 0.06722760200500488, loss_cycle 6.112916469573975, loss_id 0.26875540614128113, loss_D 0.17665749788284302\n",
      "epoch 0, loss_GAN 0.08545225858688354 0.059043172746896744, loss_cycle 7.248990058898926, loss_id 0.39995062351226807, loss_D 0.18620343506336212\n",
      "epoch 0, loss_GAN 0.048161521553993225 0.042862050235271454, loss_cycle 8.780529022216797, loss_id 0.3842320740222931, loss_D 0.18015187978744507\n",
      "epoch 0, loss_GAN 0.04226900264620781 0.04000548645853996, loss_cycle 7.0329484939575195, loss_id 0.3157530128955841, loss_D 0.15014274418354034\n",
      "epoch 0, loss_GAN 0.03504399210214615 0.037136781960725784, loss_cycle 7.340668678283691, loss_id 0.35857662558555603, loss_D 0.1385217159986496\n",
      "epoch 0, loss_GAN 0.03411833196878433 0.036434073001146317, loss_cycle 7.24287223815918, loss_id 0.35079795122146606, loss_D 0.16669020801782608\n",
      "epoch 0, loss_GAN 0.05984043702483177 0.0407201386988163, loss_cycle 6.415085315704346, loss_id 0.3172638416290283, loss_D 0.1424962878227234\n",
      "epoch 0, loss_GAN 0.04905356094241142 0.039837952703237534, loss_cycle 7.96393346786499, loss_id 0.387358695268631, loss_D 0.16631913930177689\n",
      "epoch 0, loss_GAN 0.037522442638874054 0.0329330675303936, loss_cycle 7.858165740966797, loss_id 0.40445375442504883, loss_D 0.15088491141796112\n",
      "epoch 0, loss_GAN 0.03598317876458168 0.03562666103243828, loss_cycle 6.932640552520752, loss_id 0.35001981258392334, loss_D 0.15598829835653305\n",
      "epoch 0, loss_GAN 0.036007825285196304 0.04125955328345299, loss_cycle 8.573655128479004, loss_id 0.4114122688770294, loss_D 0.15267051756381989\n",
      "epoch 0, loss_GAN 0.03688124939799309 0.08172279596328735, loss_cycle 8.598590850830078, loss_id 0.4400256872177124, loss_D 0.19299239665269852\n",
      "epoch 0, loss_GAN 0.03820938989520073 0.04372072219848633, loss_cycle 7.172083854675293, loss_id 0.37633687257766724, loss_D 0.1743532344698906\n",
      "epoch 0, loss_GAN 0.02449762262403965 0.038052719086408615, loss_cycle 7.706630706787109, loss_id 0.3314896821975708, loss_D 0.1346462108194828\n",
      "epoch 0, loss_GAN 0.023653749376535416 0.0362485833466053, loss_cycle 6.5431952476501465, loss_id 0.35415980219841003, loss_D 0.1444498971104622\n",
      "epoch 0, loss_GAN 0.03322622552514076 0.035364024341106415, loss_cycle 7.6859235763549805, loss_id 0.34410977363586426, loss_D 0.1153160035610199\n",
      "epoch 0, loss_GAN 0.05728018283843994 0.03237145021557808, loss_cycle 6.459503173828125, loss_id 0.3140007257461548, loss_D 0.1578187197446823\n",
      "epoch 0, loss_GAN 0.012874571606516838 0.03435589000582695, loss_cycle 9.813304901123047, loss_id 0.4972829520702362, loss_D 0.0957086905837059\n",
      "epoch 0, loss_GAN 0.03296785056591034 0.1529882550239563, loss_cycle 8.78113842010498, loss_id 0.4609377980232239, loss_D 0.18896909058094025\n",
      "epoch 0, loss_GAN 0.028655484318733215 0.13175401091575623, loss_cycle 7.51740837097168, loss_id 0.3855772316455841, loss_D 0.20175017416477203\n",
      "epoch 0, loss_GAN 0.028442172333598137 0.02970818243920803, loss_cycle 6.04768180847168, loss_id 0.3024590313434601, loss_D 0.10450201481580734\n",
      "epoch 0, loss_GAN 0.03690004721283913 0.06010841578245163, loss_cycle 7.8877153396606445, loss_id 0.3492898643016815, loss_D 0.21459504216909409\n",
      "epoch 0, loss_GAN 0.017766036093235016 0.054897766560316086, loss_cycle 8.813982963562012, loss_id 0.42633774876594543, loss_D 0.10993517190217972\n",
      "epoch 0, loss_GAN 0.021312739700078964 0.07888831198215485, loss_cycle 11.068934440612793, loss_id 0.5292378067970276, loss_D 0.14004438370466232\n",
      "epoch 0, loss_GAN 0.0283375084400177 0.03290918096899986, loss_cycle 7.7896552085876465, loss_id 0.37724217772483826, loss_D 0.095367431640625\n",
      "epoch 0, loss_GAN 0.018952421844005585 0.040706221014261246, loss_cycle 10.79924488067627, loss_id 0.5349457859992981, loss_D 0.07081859186291695\n",
      "epoch 0, loss_GAN 0.0188615582883358 0.038579925894737244, loss_cycle 8.987138748168945, loss_id 0.4222370982170105, loss_D 0.14137227460741997\n",
      "epoch 0, loss_GAN 0.026105618104338646 0.07380402833223343, loss_cycle 7.673540115356445, loss_id 0.3729736804962158, loss_D 0.16306889429688454\n",
      "epoch 0, loss_GAN 0.026576638221740723 0.03918222710490227, loss_cycle 10.834383964538574, loss_id 0.5063278675079346, loss_D 0.17759377881884575\n",
      "epoch 0, loss_GAN 0.0311764907091856 0.028401805087924004, loss_cycle 8.56501579284668, loss_id 0.4297526478767395, loss_D 0.08288401737809181\n",
      "epoch 0, loss_GAN 0.020461726933717728 0.025777015835046768, loss_cycle 6.860289096832275, loss_id 0.33456042408943176, loss_D 0.11002212762832642\n",
      "epoch 0, loss_GAN 0.019758153706789017 0.05565386265516281, loss_cycle 10.122027397155762, loss_id 0.47946685552597046, loss_D 0.1443948969244957\n",
      "epoch 0, loss_GAN 0.01801774837076664 0.04156256467103958, loss_cycle 9.493589401245117, loss_id 0.4551112651824951, loss_D 0.21714391186833382\n",
      "epoch 0, loss_GAN 0.0221448615193367 0.024062953889369965, loss_cycle 7.414844512939453, loss_id 0.3597319722175598, loss_D 0.15573177114129066\n",
      "epoch 0, loss_GAN 0.03271069750189781 0.04091602563858032, loss_cycle 9.381383895874023, loss_id 0.45481953024864197, loss_D 0.25324849784374237\n",
      "epoch 0, loss_GAN 0.017699971795082092 0.10650662332773209, loss_cycle 10.158771514892578, loss_id 0.4925001561641693, loss_D 0.12884599715471268\n",
      "epoch 0, loss_GAN 0.03830394521355629 0.06606359034776688, loss_cycle 5.090338706970215, loss_id 0.23031233251094818, loss_D 0.15047038346529007\n",
      "epoch 0, loss_GAN 0.06030353531241417 0.026608090847730637, loss_cycle 9.305274963378906, loss_id 0.4510515332221985, loss_D 0.11893685534596443\n",
      "epoch 0, loss_GAN 0.01799359917640686 0.051479510962963104, loss_cycle 7.413854598999023, loss_id 0.3583805561065674, loss_D 0.1129051223397255\n",
      "epoch 0, loss_GAN 0.015805000439286232 0.02182157337665558, loss_cycle 6.1913604736328125, loss_id 0.2859521508216858, loss_D 0.09871421754360199\n",
      "epoch 0, loss_GAN 0.02898077294230461 0.02174944244325161, loss_cycle 8.778982162475586, loss_id 0.4273720681667328, loss_D 0.09666687250137329\n",
      "epoch 0, loss_GAN 0.029158076271414757 0.028484757989645004, loss_cycle 7.718293190002441, loss_id 0.35955655574798584, loss_D 0.10135030746459961\n",
      "epoch 0, loss_GAN 0.03805534914135933 0.030105022713541985, loss_cycle 6.786949634552002, loss_id 0.3296962380409241, loss_D 0.12644806504249573\n",
      "epoch 0, loss_GAN 0.06614307314157486 0.0421890951693058, loss_cycle 9.045087814331055, loss_id 0.45354223251342773, loss_D 0.11334172636270523\n",
      "epoch 0, loss_GAN 0.12585967779159546 0.016664424911141396, loss_cycle 9.404173851013184, loss_id 0.46259552240371704, loss_D 0.12571491301059723\n",
      "epoch 0, loss_GAN 0.024569571018218994 0.01692141592502594, loss_cycle 6.673727035522461, loss_id 0.3136478066444397, loss_D 0.08130629919469357\n",
      "epoch 0, loss_GAN 0.016419626772403717 0.026436492800712585, loss_cycle 10.235410690307617, loss_id 0.516632080078125, loss_D 0.07015006989240646\n",
      "epoch 0, loss_GAN 0.0592038668692112 0.022152774035930634, loss_cycle 7.138340473175049, loss_id 0.36738675832748413, loss_D 0.10418160259723663\n",
      "epoch 0, loss_GAN 0.05194735899567604 0.018271056935191154, loss_cycle 7.785086631774902, loss_id 0.3800044357776642, loss_D 0.09861283004283905\n",
      "epoch 0, loss_GAN 0.030748210847377777 0.02007695473730564, loss_cycle 7.2286057472229, loss_id 0.3730204105377197, loss_D 0.07673760503530502\n",
      "epoch 0, loss_GAN 0.015001003630459309 0.016313031315803528, loss_cycle 6.894824504852295, loss_id 0.31428539752960205, loss_D 0.08018998801708221\n",
      "epoch 0, loss_GAN 0.013870066031813622 0.03018283098936081, loss_cycle 8.567464828491211, loss_id 0.4150831699371338, loss_D 0.08479752764105797\n",
      "epoch 0, loss_GAN 0.018612921237945557 0.01210212055593729, loss_cycle 6.3085455894470215, loss_id 0.3405076861381531, loss_D 0.06015371158719063\n",
      "epoch 0, loss_GAN 0.016464516520500183 0.013873507268726826, loss_cycle 6.593568325042725, loss_id 0.33027952909469604, loss_D 0.06438539363443851\n",
      "epoch 0, loss_GAN 0.02020561322569847 0.03696589916944504, loss_cycle 8.690845489501953, loss_id 0.37383776903152466, loss_D 0.08101008832454681\n",
      "epoch 0, loss_GAN 0.06895817071199417 0.05148710682988167, loss_cycle 8.794904708862305, loss_id 0.4009745121002197, loss_D 0.14278465509414673\n",
      "epoch 0, loss_GAN 0.06405981630086899 0.013952398672699928, loss_cycle 7.096837043762207, loss_id 0.3656634986400604, loss_D 0.0901748463511467\n",
      "epoch 0, loss_GAN 0.02179754711687565 0.02529660053551197, loss_cycle 8.570198059082031, loss_id 0.4139575958251953, loss_D 0.06550992652773857\n",
      "epoch 0, loss_GAN 0.015057130716741085 0.027334162965416908, loss_cycle 8.952407836914062, loss_id 0.3841126561164856, loss_D 0.06616063788533211\n",
      "epoch 0, loss_GAN 0.01586313359439373 0.02357836812734604, loss_cycle 6.70628547668457, loss_id 0.33136188983917236, loss_D 0.05511929839849472\n",
      "epoch 0, loss_GAN 0.02184598334133625 0.016024893149733543, loss_cycle 6.407441139221191, loss_id 0.31649306416511536, loss_D 0.055613525211811066\n",
      "epoch 0, loss_GAN 0.0201380867511034 0.01587691158056259, loss_cycle 8.562707901000977, loss_id 0.42263978719711304, loss_D 0.0661484394222498\n",
      "epoch 0, loss_GAN 0.017647525295615196 0.013407359831035137, loss_cycle 8.141039848327637, loss_id 0.41593000292778015, loss_D 0.06400853022933006\n",
      "epoch 0, loss_GAN 0.02371841110289097 0.017322486266493797, loss_cycle 7.702753067016602, loss_id 0.3874589502811432, loss_D 0.06206046789884567\n",
      "epoch 0, loss_GAN 0.023645833134651184 0.01958659291267395, loss_cycle 7.426471710205078, loss_id 0.34128886461257935, loss_D 0.08658772706985474\n",
      "epoch 0, loss_GAN 0.04551361873745918 0.018632639199495316, loss_cycle 7.495226860046387, loss_id 0.3835473656654358, loss_D 0.08534512855112553\n",
      "epoch 0, loss_GAN 0.01493910327553749 0.010972737334668636, loss_cycle 5.692249298095703, loss_id 0.29914921522140503, loss_D 0.039948102086782455\n",
      "epoch 0, loss_GAN 0.0218910314142704 0.07649857550859451, loss_cycle 10.624499320983887, loss_id 0.4750920534133911, loss_D 0.1000332199037075\n",
      "epoch 0, loss_GAN 0.016023555770516396 0.01819201186299324, loss_cycle 7.08060359954834, loss_id 0.3547991216182709, loss_D 0.05793503299355507\n",
      "epoch 0, loss_GAN 0.009462395682930946 0.02747984230518341, loss_cycle 7.58373498916626, loss_id 0.3588172197341919, loss_D 0.05309273675084114\n",
      "epoch 0, loss_GAN 0.03641270101070404 0.01735088601708412, loss_cycle 9.188231468200684, loss_id 0.42090991139411926, loss_D 0.10684477165341377\n",
      "epoch 0, loss_GAN 0.03041723743081093 0.12923069298267365, loss_cycle 6.100234031677246, loss_id 0.3064780831336975, loss_D 0.1442488506436348\n",
      "epoch 0, loss_GAN 0.032797228544950485 0.0533624105155468, loss_cycle 9.391927719116211, loss_id 0.4536491930484772, loss_D 0.08399368077516556\n",
      "epoch 0, loss_GAN 0.01171073131263256 0.013399914838373661, loss_cycle 8.869370460510254, loss_id 0.41916781663894653, loss_D 0.036423010751605034\n",
      "epoch 0, loss_GAN 0.02681819349527359 0.032370828092098236, loss_cycle 9.279170036315918, loss_id 0.45646440982818604, loss_D 0.06791870482265949\n",
      "epoch 0, loss_GAN 0.010263296775519848 0.018728069961071014, loss_cycle 10.012531280517578, loss_id 0.5358375906944275, loss_D 0.045097989961504936\n",
      "epoch 0, loss_GAN 0.02673989161849022 0.0326656848192215, loss_cycle 5.9976348876953125, loss_id 0.29543688893318176, loss_D 0.07626623660326004\n",
      "epoch 0, loss_GAN 0.009319041855633259 0.015478272922337055, loss_cycle 8.575783729553223, loss_id 0.3922539949417114, loss_D 0.0455289576202631\n",
      "epoch 0, loss_GAN 0.023071404546499252 0.013913743197917938, loss_cycle 6.831475257873535, loss_id 0.31360214948654175, loss_D 0.05751371756196022\n",
      "epoch 0, loss_GAN 0.013657731004059315 0.028145279735326767, loss_cycle 7.152352809906006, loss_id 0.3215022087097168, loss_D 0.07435592450201511\n",
      "epoch 0, loss_GAN 0.03171451389789581 0.0540514811873436, loss_cycle 8.510400772094727, loss_id 0.37761908769607544, loss_D 0.09648691490292549\n",
      "epoch 0, loss_GAN 0.02754279598593712 0.021191373467445374, loss_cycle 6.236156463623047, loss_id 0.2959595322608948, loss_D 0.08945455402135849\n",
      "epoch 0, loss_GAN 0.026875702664256096 0.013898203149437904, loss_cycle 8.732295036315918, loss_id 0.4507846534252167, loss_D 0.05640012212097645\n",
      "epoch 0, loss_GAN 0.01095566712319851 0.01779123581945896, loss_cycle 10.480125427246094, loss_id 0.46626153588294983, loss_D 0.06092352047562599\n",
      "epoch 0, loss_GAN 0.013971639797091484 0.009770832024514675, loss_cycle 5.526608467102051, loss_id 0.27117305994033813, loss_D 0.03721451200544834\n",
      "epoch 0, loss_GAN 0.023386115208268166 0.01852569542825222, loss_cycle 10.784764289855957, loss_id 0.5659322738647461, loss_D 0.0580088347196579\n",
      "epoch 0, loss_GAN 0.01531756017357111 0.01628701202571392, loss_cycle 9.086188316345215, loss_id 0.4946620464324951, loss_D 0.05240495875477791\n",
      "epoch 0, loss_GAN 0.028155911713838577 0.09939663857221603, loss_cycle 8.63410472869873, loss_id 0.4875466227531433, loss_D 0.10840485244989395\n",
      "epoch 0, loss_GAN 0.029912767931818962 0.017619408667087555, loss_cycle 5.772202014923096, loss_id 0.3436337113380432, loss_D 0.07828555628657341\n",
      "epoch 0, loss_GAN 0.014337965287268162 0.019873488694429398, loss_cycle 7.439711570739746, loss_id 0.22631031274795532, loss_D 0.04637924022972584\n",
      "epoch 0, loss_GAN 0.04603724181652069 0.012930130586028099, loss_cycle 5.685365676879883, loss_id 0.3215706944465637, loss_D 0.07305150851607323\n",
      "epoch 0, loss_GAN 0.03133655712008476 0.05659918859601021, loss_cycle 9.026323318481445, loss_id 0.4819769561290741, loss_D 0.08029009401798248\n",
      "epoch 0, loss_GAN 0.015814928337931633 0.03611241653561592, loss_cycle 8.744895935058594, loss_id 0.4116334319114685, loss_D 0.08206738531589508\n",
      "epoch 0, loss_GAN 0.019945772364735603 0.025863902643322945, loss_cycle 8.550544738769531, loss_id 0.36329057812690735, loss_D 0.05859135463833809\n",
      "epoch 0, loss_GAN 0.02556087076663971 0.01356632448732853, loss_cycle 7.5975775718688965, loss_id 0.34880679845809937, loss_D 0.05070473067462444\n",
      "epoch 0, loss_GAN 0.015320220030844212 0.04334785416722298, loss_cycle 7.216994762420654, loss_id 0.3653278946876526, loss_D 0.05927087925374508\n",
      "epoch 0, loss_GAN 0.01687820814549923 0.032397083938121796, loss_cycle 6.169214725494385, loss_id 0.31274256110191345, loss_D 0.06139454245567322\n",
      "epoch 0, loss_GAN 0.01154434122145176 0.02265775017440319, loss_cycle 7.45610237121582, loss_id 0.4240642488002777, loss_D 0.04749932698905468\n",
      "epoch 0, loss_GAN 0.014468966983258724 0.013643192127346992, loss_cycle 5.8161139488220215, loss_id 0.4464759826660156, loss_D 0.0394822433590889\n",
      "epoch 0, loss_GAN 0.046156853437423706 0.024270717054605484, loss_cycle 7.035423278808594, loss_id 0.37945833802223206, loss_D 0.09253017604351044\n",
      "epoch 0, loss_GAN 0.03559314087033272 0.07862774282693863, loss_cycle 8.87520694732666, loss_id 0.3542150855064392, loss_D 0.09152493625879288\n",
      "epoch 0, loss_GAN 0.0713919922709465 0.06390836089849472, loss_cycle 6.281402111053467, loss_id 0.32675468921661377, loss_D 0.15836627781391144\n",
      "epoch 0, loss_GAN 0.05974021181464195 0.053236182779073715, loss_cycle 9.711881637573242, loss_id 0.46397465467453003, loss_D 0.11904867738485336\n",
      "epoch 0, loss_GAN 0.04465511441230774 0.022246360778808594, loss_cycle 6.291928291320801, loss_id 0.3231847584247589, loss_D 0.05632467940449715\n",
      "epoch 0, loss_GAN 0.04424091801047325 0.0072345915250480175, loss_cycle 9.808099746704102, loss_id 0.4117996096611023, loss_D 0.08306950703263283\n",
      "epoch 0, loss_GAN 0.02463296614587307 0.05930126830935478, loss_cycle 7.415799140930176, loss_id 0.36397606134414673, loss_D 0.07050280272960663\n",
      "epoch 0, loss_GAN 0.022784249857068062 0.015782155096530914, loss_cycle 8.009712219238281, loss_id 0.3783525824546814, loss_D 0.07432400062680244\n",
      "epoch 0, loss_GAN 0.013117480091750622 0.033052366226911545, loss_cycle 8.460244178771973, loss_id 0.40866026282310486, loss_D 0.07282773777842522\n",
      "epoch 0, loss_GAN 0.00917553436011076 0.012354366481304169, loss_cycle 5.574053764343262, loss_id 0.28150248527526855, loss_D 0.04016849584877491\n",
      "epoch 0, loss_GAN 0.008007995784282684 0.010587689466774464, loss_cycle 6.783758163452148, loss_id 0.35413604974746704, loss_D 0.029086222872138023\n",
      "epoch 0, loss_GAN 0.02575804851949215 0.03399701416492462, loss_cycle 6.6629791259765625, loss_id 0.3306937515735626, loss_D 0.06360329501330853\n",
      "epoch 0, loss_GAN 0.033054009079933167 0.04711390286684036, loss_cycle 9.541011810302734, loss_id 0.49980640411376953, loss_D 0.0715191662311554\n",
      "epoch 0, loss_GAN 0.01156457606703043 0.027683403342962265, loss_cycle 6.523175239562988, loss_id 0.349719762802124, loss_D 0.057063447311520576\n",
      "epoch 0, loss_GAN 0.009432814083993435 0.014791681431233883, loss_cycle 6.913363933563232, loss_id 0.2819790840148926, loss_D 0.0353841669857502\n",
      "epoch 0, loss_GAN 0.016055569052696228 0.015820376574993134, loss_cycle 7.234809398651123, loss_id 0.33057743310928345, loss_D 0.036018382757902145\n",
      "epoch 0, loss_GAN 0.010877571068704128 0.013194464147090912, loss_cycle 6.711216926574707, loss_id 0.3552934527397156, loss_D 0.032774755731225014\n",
      "epoch 0, loss_GAN 0.016589399427175522 0.03240782395005226, loss_cycle 8.7608642578125, loss_id 0.41436463594436646, loss_D 0.05927970074117184\n",
      "epoch 0, loss_GAN 0.010768433101475239 0.025929948315024376, loss_cycle 6.937210559844971, loss_id 0.46883583068847656, loss_D 0.03972904197871685\n",
      "epoch 0, loss_GAN 0.015446173958480358 0.009396422654390335, loss_cycle 7.853980541229248, loss_id 0.33443504571914673, loss_D 0.04390336386859417\n",
      "epoch 0, loss_GAN 0.009945343248546124 0.01314567495137453, loss_cycle 6.440810203552246, loss_id 0.2843988239765167, loss_D 0.03179039806127548\n",
      "epoch 0, loss_GAN 0.00742702279239893 0.010204889811575413, loss_cycle 6.549549102783203, loss_id 0.3479551672935486, loss_D 0.031513579189777374\n",
      "epoch 0, loss_GAN 0.07467500120401382 0.0076211667619645596, loss_cycle 3.8572874069213867, loss_id 0.19307008385658264, loss_D 0.11588150262832642\n",
      "epoch 0, loss_GAN 0.029351171106100082 0.04073881357908249, loss_cycle 7.043314456939697, loss_id 0.410189688205719, loss_D 0.08460192382335663\n",
      "epoch 0, loss_GAN 0.020506376400589943 0.019426405429840088, loss_cycle 6.882229804992676, loss_id 0.2465948760509491, loss_D 0.06664768233895302\n",
      "epoch 0, loss_GAN 0.020697984844446182 0.02453754097223282, loss_cycle 6.185083866119385, loss_id 0.3859783411026001, loss_D 0.0717234667390585\n",
      "epoch 0, loss_GAN 0.012293442152440548 0.052652496844530106, loss_cycle 6.82800817489624, loss_id 0.27319568395614624, loss_D 0.07993211038410664\n",
      "epoch 0, loss_GAN 0.01653272472321987 0.027489077299833298, loss_cycle 6.142280101776123, loss_id 0.2771953344345093, loss_D 0.04726281017065048\n",
      "epoch 0, loss_GAN 0.012356912717223167 0.018129436299204826, loss_cycle 6.462172985076904, loss_id 0.3396027088165283, loss_D 0.04248434491455555\n",
      "epoch 0, loss_GAN 0.011003294959664345 0.013662940822541714, loss_cycle 7.012247085571289, loss_id 0.33278077840805054, loss_D 0.050574323162436485\n",
      "epoch 0, loss_GAN 0.013937991112470627 0.009370903484523296, loss_cycle 7.033439636230469, loss_id 0.39453980326652527, loss_D 0.026982620358467102\n",
      "epoch 0, loss_GAN 0.01816493645310402 0.009332898072898388, loss_cycle 7.910647392272949, loss_id 0.3950237035751343, loss_D 0.056267134845256805\n",
      "epoch 0, loss_GAN 0.05505160987377167 0.02891395427286625, loss_cycle 4.6285481452941895, loss_id 0.19251982867717743, loss_D 0.07835729792714119\n",
      "epoch 0, loss_GAN 0.028916610404849052 0.014186718501150608, loss_cycle 6.627181053161621, loss_id 0.30225828289985657, loss_D 0.07430025562644005\n",
      "epoch 0, loss_GAN 0.04673052206635475 0.016106922179460526, loss_cycle 7.908592700958252, loss_id 0.3731260895729065, loss_D 0.05571563541889191\n",
      "epoch 0, loss_GAN 0.012694797478616238 0.007647531572729349, loss_cycle 5.262826919555664, loss_id 0.2185845673084259, loss_D 0.04031682200729847\n",
      "epoch 0, loss_GAN 0.01795298047363758 0.010601913556456566, loss_cycle 7.480266571044922, loss_id 0.389753133058548, loss_D 0.05031035467982292\n",
      "epoch 0, loss_GAN 0.018975837156176567 0.01883023791015148, loss_cycle 6.197521686553955, loss_id 0.37770360708236694, loss_D 0.04776160418987274\n",
      "epoch 0, loss_GAN 0.017876574769616127 0.010247405618429184, loss_cycle 6.6449432373046875, loss_id 0.4200211465358734, loss_D 0.03927707485854626\n",
      "epoch 0, loss_GAN 0.019013702869415283 0.017592214047908783, loss_cycle 5.284618377685547, loss_id 0.33806130290031433, loss_D 0.055483462288975716\n",
      "epoch 0, loss_GAN 0.011009182780981064 0.06996303051710129, loss_cycle 8.510685920715332, loss_id 0.4350777268409729, loss_D 0.08112111873924732\n",
      "epoch 0, loss_GAN 0.013685185462236404 0.062364380806684494, loss_cycle 5.650832653045654, loss_id 0.38639384508132935, loss_D 0.08774015307426453\n",
      "epoch 0, loss_GAN 0.023936789482831955 0.04274754226207733, loss_cycle 6.092318534851074, loss_id 0.3324953019618988, loss_D 0.07041339576244354\n",
      "epoch 0, loss_GAN 0.016784192994236946 0.034430716186761856, loss_cycle 6.89057731628418, loss_id 0.3131183385848999, loss_D 0.05037865601480007\n",
      "epoch 0, loss_GAN 0.03211157023906708 0.0071010589599609375, loss_cycle 7.43747615814209, loss_id 0.30695241689682007, loss_D 0.04190879222005606\n",
      "epoch 0, loss_GAN 0.013097896240651608 0.02777688018977642, loss_cycle 6.657307147979736, loss_id 0.4046410918235779, loss_D 0.03936393745243549\n",
      "epoch 0, loss_GAN 0.00827226135879755 0.01850431226193905, loss_cycle 5.509288311004639, loss_id 0.317446768283844, loss_D 0.04057670570909977\n",
      "epoch 0, loss_GAN 0.02154872566461563 0.028354082256555557, loss_cycle 6.960697174072266, loss_id 0.3805358111858368, loss_D 0.0493021234869957\n",
      "epoch 0, loss_GAN 0.011505995877087116 0.02151867374777794, loss_cycle 7.6670098304748535, loss_id 0.38624584674835205, loss_D 0.060260120779275894\n",
      "epoch 0, loss_GAN 0.01008286140859127 0.05316178500652313, loss_cycle 6.926809310913086, loss_id 0.33707934617996216, loss_D 0.06599437072873116\n",
      "epoch 0, loss_GAN 0.011244328692555428 0.032361529767513275, loss_cycle 5.711941719055176, loss_id 0.3052758574485779, loss_D 0.04825263470411301\n",
      "epoch 0, loss_GAN 0.009648667648434639 0.009955735877156258, loss_cycle 4.996148109436035, loss_id 0.3087860345840454, loss_D 0.025600407272577286\n",
      "epoch 0, loss_GAN 0.017986632883548737 0.02439049631357193, loss_cycle 7.292377948760986, loss_id 0.3993508219718933, loss_D 0.03722941875457764\n",
      "epoch 0, loss_GAN 0.005770848598331213 0.012596662156283855, loss_cycle 7.153103828430176, loss_id 0.3211621344089508, loss_D 0.03225700743496418\n",
      "epoch 0, loss_GAN 0.00598825141787529 0.018086111173033714, loss_cycle 6.865562438964844, loss_id 0.29380080103874207, loss_D 0.031017168425023556\n",
      "epoch 0, loss_GAN 0.011663893237709999 0.01902255043387413, loss_cycle 7.720978260040283, loss_id 0.40047186613082886, loss_D 0.045700978487730026\n",
      "epoch 0, loss_GAN 0.01803870126605034 0.022441847249865532, loss_cycle 5.60050106048584, loss_id 0.32418036460876465, loss_D 0.04615051671862602\n",
      "epoch 0, loss_GAN 0.005627485923469067 0.02388717420399189, loss_cycle 5.2942633628845215, loss_id 0.25649234652519226, loss_D 0.040878722444176674\n",
      "epoch 0, loss_GAN 0.015764106065034866 0.007532527670264244, loss_cycle 7.778390884399414, loss_id 0.37562137842178345, loss_D 0.030020371079444885\n",
      "epoch 0, loss_GAN 0.01103913877159357 0.01505362894386053, loss_cycle 5.890626430511475, loss_id 0.3252299427986145, loss_D 0.02601771429181099\n",
      "epoch 0, loss_GAN 0.010746307671070099 0.004724439233541489, loss_cycle 5.336895942687988, loss_id 0.2553871273994446, loss_D 0.030254719778895378\n",
      "epoch 0, loss_GAN 0.006477725226432085 0.00865848921239376, loss_cycle 6.452836990356445, loss_id 0.3016107678413391, loss_D 0.02845543995499611\n",
      "epoch 0, loss_GAN 0.02026633359491825 0.011308505199849606, loss_cycle 6.779954433441162, loss_id 0.30799102783203125, loss_D 0.03802029229700565\n",
      "epoch 0, loss_GAN 0.005350514780730009 0.019395003095269203, loss_cycle 4.313172340393066, loss_id 0.22267931699752808, loss_D 0.027919805608689785\n",
      "epoch 0, loss_GAN 0.009859181009232998 0.00600298261269927, loss_cycle 6.732668876647949, loss_id 0.32468900084495544, loss_D 0.02424085419625044\n",
      "epoch 0, loss_GAN 0.03075163997709751 0.009129560552537441, loss_cycle 9.458182334899902, loss_id 0.4420419931411743, loss_D 0.04322012513875961\n",
      "epoch 0, loss_GAN 0.01700461097061634 0.008285535499453545, loss_cycle 6.623489856719971, loss_id 0.3336566686630249, loss_D 0.040962666273117065\n",
      "epoch 0, loss_GAN 0.009607437066733837 0.009056130424141884, loss_cycle 4.714541912078857, loss_id 0.2592540681362152, loss_D 0.028074124827980995\n",
      "epoch 0, loss_GAN 0.005702434107661247 0.009507467970252037, loss_cycle 4.565549373626709, loss_id 0.2859782576560974, loss_D 0.021507233381271362\n",
      "epoch 0, loss_GAN 0.012395753525197506 0.005474429577589035, loss_cycle 4.617943286895752, loss_id 0.23070740699768066, loss_D 0.03768066968768835\n",
      "epoch 0, loss_GAN 0.006652113050222397 0.02815174125134945, loss_cycle 7.364754676818848, loss_id 0.4083464443683624, loss_D 0.04373367875814438\n",
      "epoch 0, loss_GAN 0.0170344989746809 0.020496705546975136, loss_cycle 6.131777286529541, loss_id 0.27355438470840454, loss_D 0.03880731761455536\n",
      "epoch 0, loss_GAN 0.022032421082258224 0.008291486650705338, loss_cycle 5.433063507080078, loss_id 0.3036201298236847, loss_D 0.036509839817881584\n",
      "epoch 0, loss_GAN 0.010991232469677925 0.009495357051491737, loss_cycle 5.289661884307861, loss_id 0.21330928802490234, loss_D 0.028048157691955566\n",
      "epoch 0, loss_GAN 0.011389699764549732 0.006643232889473438, loss_cycle 6.358883380889893, loss_id 0.36676377058029175, loss_D 0.026848040521144867\n",
      "epoch 0, loss_GAN 0.011866260319948196 0.010486575774848461, loss_cycle 5.31733512878418, loss_id 0.2812465727329254, loss_D 0.02539757825434208\n",
      "epoch 0, loss_GAN 0.005458168685436249 0.007799441926181316, loss_cycle 6.149342060089111, loss_id 0.2699011564254761, loss_D 0.022321236319839954\n",
      "epoch 0, loss_GAN 0.005556797608733177 0.005901033524423838, loss_cycle 5.147076606750488, loss_id 0.2450805902481079, loss_D 0.02060043904930353\n",
      "epoch 0, loss_GAN 0.008627661503851414 0.010560186579823494, loss_cycle 5.259956359863281, loss_id 0.2900831997394562, loss_D 0.020174250937998295\n",
      "epoch 0, loss_GAN 0.023232372477650642 0.006463860627263784, loss_cycle 6.063185691833496, loss_id 0.31165534257888794, loss_D 0.03094603680074215\n",
      "epoch 0, loss_GAN 0.012977669015526772 0.00992920994758606, loss_cycle 6.245497703552246, loss_id 0.3529338836669922, loss_D 0.04308798909187317\n",
      "epoch 0, loss_GAN 0.008239788003265858 0.00959246139973402, loss_cycle 8.89494514465332, loss_id 0.39861786365509033, loss_D 0.03412987105548382\n",
      "epoch 0, loss_GAN 0.00830105971544981 0.012764034792780876, loss_cycle 5.697945594787598, loss_id 0.2675764560699463, loss_D 0.026454659178853035\n",
      "epoch 0, loss_GAN 0.0071980212815105915 0.010810193605720997, loss_cycle 6.291472911834717, loss_id 0.3233453631401062, loss_D 0.025907951407134533\n",
      "epoch 0, loss_GAN 0.005014645867049694 0.005678657442331314, loss_cycle 5.02780818939209, loss_id 0.2169598639011383, loss_D 0.01738647185266018\n",
      "epoch 0, loss_GAN 0.010453573428094387 0.01909356564283371, loss_cycle 4.918918609619141, loss_id 0.23590393364429474, loss_D 0.03217695280909538\n",
      "epoch 0, loss_GAN 0.006698021665215492 0.013034685514867306, loss_cycle 7.538384437561035, loss_id 0.410322368144989, loss_D 0.03095153719186783\n",
      "epoch 0, loss_GAN 0.006794313434511423 0.003985367249697447, loss_cycle 4.704753875732422, loss_id 0.1978207528591156, loss_D 0.013902771286666393\n",
      "epoch 0, loss_GAN 0.007122633513063192 0.006182693876326084, loss_cycle 6.034974098205566, loss_id 0.2471599131822586, loss_D 0.019740679301321507\n",
      "epoch 0, loss_GAN 0.008037403225898743 0.023584382608532906, loss_cycle 5.222205638885498, loss_id 0.2685188055038452, loss_D 0.0470687635242939\n",
      "epoch 0, loss_GAN 0.009510286152362823 0.010266212746500969, loss_cycle 5.973057746887207, loss_id 0.2858033776283264, loss_D 0.03133421391248703\n",
      "epoch 0, loss_GAN 0.00650081317871809 0.003981676418334246, loss_cycle 8.274480819702148, loss_id 0.41396230459213257, loss_D 0.014654192142188549\n",
      "epoch 0, loss_GAN 0.005253320559859276 0.007578318007290363, loss_cycle 7.2518391609191895, loss_id 0.318345308303833, loss_D 0.026038133539259434\n",
      "epoch 0, loss_GAN 0.007092608604580164 0.0056609357707202435, loss_cycle 5.387567520141602, loss_id 0.26744967699050903, loss_D 0.021897386759519577\n",
      "epoch 0, loss_GAN 0.007502011489123106 0.0056269168853759766, loss_cycle 4.706799030303955, loss_id 0.22400037944316864, loss_D 0.018955832347273827\n",
      "epoch 0, loss_GAN 0.010311287827789783 0.005157330073416233, loss_cycle 4.467929363250732, loss_id 0.2251412570476532, loss_D 0.020618341863155365\n",
      "epoch 0, loss_GAN 0.008004672825336456 0.007207539398223162, loss_cycle 6.617551326751709, loss_id 0.3505839705467224, loss_D 0.02930485177785158\n",
      "epoch 0, loss_GAN 0.012945819646120071 0.005035329144448042, loss_cycle 7.596538066864014, loss_id 0.34293192625045776, loss_D 0.04069565050303936\n",
      "epoch 0, loss_GAN 0.010550028644502163 0.004547115880995989, loss_cycle 6.757012367248535, loss_id 0.3478895425796509, loss_D 0.02684404980391264\n",
      "epoch 0, loss_GAN 0.00604685815051198 0.01115226000547409, loss_cycle 6.302762031555176, loss_id 0.29065605998039246, loss_D 0.034621432423591614\n",
      "epoch 0, loss_GAN 0.013431875966489315 0.010213544592261314, loss_cycle 6.155744552612305, loss_id 0.3132128119468689, loss_D 0.03179723955690861\n",
      "epoch 0, loss_GAN 0.00986366719007492 0.019712969660758972, loss_cycle 8.590633392333984, loss_id 0.43586039543151855, loss_D 0.03758617676794529\n",
      "epoch 0, loss_GAN 0.005758053623139858 0.01314552966505289, loss_cycle 7.125629901885986, loss_id 0.297893226146698, loss_D 0.02556585520505905\n",
      "epoch 0, loss_GAN 0.005590504501014948 0.008534069173038006, loss_cycle 7.508121490478516, loss_id 0.3711290955543518, loss_D 0.026910625398159027\n",
      "epoch 0, loss_GAN 0.00760086253285408 0.00694311922416091, loss_cycle 6.168974876403809, loss_id 0.26270797848701477, loss_D 0.02344762161374092\n",
      "epoch 0, loss_GAN 0.006556302774697542 0.008273595944046974, loss_cycle 5.81392765045166, loss_id 0.2672080993652344, loss_D 0.025897454470396042\n",
      "epoch 0, loss_GAN 0.012038310058414936 0.005043591372668743, loss_cycle 8.420646667480469, loss_id 0.37452924251556396, loss_D 0.029195774346590042\n",
      "epoch 0, loss_GAN 0.004078753758221865 0.005407324526458979, loss_cycle 5.212420463562012, loss_id 0.23839744925498962, loss_D 0.0191578296944499\n",
      "epoch 0, loss_GAN 0.009671453386545181 0.005305224563926458, loss_cycle 6.2833380699157715, loss_id 0.28880202770233154, loss_D 0.025889314711093903\n",
      "epoch 0, loss_GAN 0.00561069929972291 0.004759267438203096, loss_cycle 6.322147846221924, loss_id 0.30063390731811523, loss_D 0.020215295255184174\n",
      "epoch 0, loss_GAN 0.006130622234195471 0.006201199255883694, loss_cycle 6.391885280609131, loss_id 0.31369584798812866, loss_D 0.017037075012922287\n",
      "epoch 0, loss_GAN 0.009815769270062447 0.005427316762506962, loss_cycle 6.119835376739502, loss_id 0.27802151441574097, loss_D 0.02167997881770134\n",
      "epoch 0, loss_GAN 0.006865112576633692 0.005192683544009924, loss_cycle 4.557338714599609, loss_id 0.22647590935230255, loss_D 0.01931659411638975\n",
      "epoch 0, loss_GAN 0.009469361044466496 0.0042258803732693195, loss_cycle 4.981650352478027, loss_id 0.22972537577152252, loss_D 0.019362631253898144\n",
      "epoch 0, loss_GAN 0.005593626294285059 0.004020452033728361, loss_cycle 7.436611652374268, loss_id 0.3570443391799927, loss_D 0.018763535656034946\n",
      "epoch 0, loss_GAN 0.004929989110678434 0.005776315461844206, loss_cycle 9.11603832244873, loss_id 0.4328671991825104, loss_D 0.01645471341907978\n",
      "epoch 0, loss_GAN 0.004985279403626919 0.007968046702444553, loss_cycle 6.149450302124023, loss_id 0.283000111579895, loss_D 0.021346794441342354\n",
      "epoch 0, loss_GAN 0.007474114187061787 0.004486542195081711, loss_cycle 4.859745979309082, loss_id 0.22087401151657104, loss_D 0.020825387444347143\n",
      "epoch 0, loss_GAN 0.005623776465654373 0.006241847760975361, loss_cycle 6.648127555847168, loss_id 0.32185089588165283, loss_D 0.02460731938481331\n",
      "epoch 0, loss_GAN 0.010493393987417221 0.0056803347542881966, loss_cycle 5.235382080078125, loss_id 0.24931541085243225, loss_D 0.02323033381253481\n",
      "epoch 0, loss_GAN 0.0052115460857748985 0.007076072972267866, loss_cycle 7.618376731872559, loss_id 0.3708663582801819, loss_D 0.01745484210550785\n",
      "epoch 0, loss_GAN 0.007097908761352301 0.005148438271135092, loss_cycle 5.663173198699951, loss_id 0.2530871033668518, loss_D 0.025363797321915627\n",
      "epoch 0, loss_GAN 0.002794349566102028 0.004001247696578503, loss_cycle 5.710898399353027, loss_id 0.2849080562591553, loss_D 0.008156391326338053\n",
      "epoch 0, loss_GAN 0.004979014862328768 0.0040981885977089405, loss_cycle 5.892427444458008, loss_id 0.30413344502449036, loss_D 0.015292584896087646\n",
      "epoch 0, loss_GAN 0.01625749282538891 0.004876419901847839, loss_cycle 7.378248691558838, loss_id 0.3693959712982178, loss_D 0.03262114617973566\n",
      "epoch 0, loss_GAN 0.004468400962650776 0.005491696763783693, loss_cycle 5.90954065322876, loss_id 0.2733355164527893, loss_D 0.019462955184280872\n",
      "epoch 0, loss_GAN 0.004451731685549021 0.00585253955796361, loss_cycle 7.551946640014648, loss_id 0.32098159193992615, loss_D 0.01850166916847229\n",
      "epoch 0, loss_GAN 0.006720141042023897 0.003423278219997883, loss_cycle 8.584453582763672, loss_id 0.4505073130130768, loss_D 0.014090649783611298\n",
      "epoch 0, loss_GAN 0.002564719645306468 0.004401187412440777, loss_cycle 5.847664833068848, loss_id 0.29951563477516174, loss_D 0.014117115177214146\n",
      "epoch 0, loss_GAN 0.009293140843510628 0.007515791803598404, loss_cycle 6.314752101898193, loss_id 0.327600359916687, loss_D 0.020239601843059063\n",
      "epoch 0, loss_GAN 0.004255970474332571 0.01068202592432499, loss_cycle 4.591041564941406, loss_id 0.24801871180534363, loss_D 0.024492190219461918\n",
      "epoch 0, loss_GAN 0.006654803175479174 0.0051854876801371574, loss_cycle 6.7163920402526855, loss_id 0.2961059808731079, loss_D 0.0203006723895669\n",
      "epoch 0, loss_GAN 0.0039761969819664955 0.004044920671731234, loss_cycle 5.595948219299316, loss_id 0.3111705482006073, loss_D 0.012609779834747314\n",
      "epoch 0, loss_GAN 0.00813330803066492 0.00276781152933836, loss_cycle 6.182250022888184, loss_id 0.25307318568229675, loss_D 0.016716767568141222\n",
      "epoch 0, loss_GAN 0.003222753992304206 0.004126149229705334, loss_cycle 4.570314407348633, loss_id 0.21456000208854675, loss_D 0.013345272745937109\n",
      "epoch 0, loss_GAN 0.003287194762378931 0.00419893441721797, loss_cycle 7.252236366271973, loss_id 0.32295939326286316, loss_D 0.017859814688563347\n",
      "epoch 0, loss_GAN 0.005147992167621851 0.008573559112846851, loss_cycle 5.386381149291992, loss_id 0.28341490030288696, loss_D 0.02178136073052883\n",
      "epoch 0, loss_GAN 0.004315279424190521 0.00397067004814744, loss_cycle 4.288474082946777, loss_id 0.2509780824184418, loss_D 0.011296703480184078\n",
      "epoch 0, loss_GAN 0.004616474267095327 0.006727059371769428, loss_cycle 4.577365875244141, loss_id 0.23684638738632202, loss_D 0.016557037830352783\n",
      "epoch 0, loss_GAN 0.01909555308520794 0.00504759605973959, loss_cycle 7.638011932373047, loss_id 0.3899208903312683, loss_D 0.032440509647130966\n",
      "epoch 0, loss_GAN 0.005078807473182678 0.006128387060016394, loss_cycle 7.006199359893799, loss_id 0.3591616749763489, loss_D 0.01694112503901124\n",
      "epoch 0, loss_GAN 0.004416969604790211 0.0031422413885593414, loss_cycle 4.941415309906006, loss_id 0.27237221598625183, loss_D 0.013484367169439793\n",
      "epoch 0, loss_GAN 0.004707772750407457 0.010385019704699516, loss_cycle 5.489892959594727, loss_id 0.30817049741744995, loss_D 0.028114707209169865\n",
      "epoch 0, loss_GAN 0.005676186177879572 0.0027090588118880987, loss_cycle 4.558621883392334, loss_id 0.2006974220275879, loss_D 0.011871180962771177\n",
      "epoch 0, loss_GAN 0.010766162537038326 0.0060708243399858475, loss_cycle 5.460773468017578, loss_id 0.25890010595321655, loss_D 0.02945572230964899\n",
      "epoch 0, loss_GAN 0.010628486052155495 0.00751697039231658, loss_cycle 8.948753356933594, loss_id 0.4753943085670471, loss_D 0.022233170457184315\n",
      "epoch 0, loss_GAN 0.0034811757504940033 0.0040343767032027245, loss_cycle 7.415968894958496, loss_id 0.3627130389213562, loss_D 0.010853663086891174\n",
      "epoch 0, loss_GAN 0.0031513290014117956 0.0020860994700342417, loss_cycle 5.020849227905273, loss_id 0.22298385202884674, loss_D 0.009384538512676954\n",
      "epoch 0, loss_GAN 0.00940463226288557 0.005587040912359953, loss_cycle 6.464681625366211, loss_id 0.3130001425743103, loss_D 0.022914014756679535\n",
      "epoch 0, loss_GAN 0.010740314610302448 0.006732841022312641, loss_cycle 4.472969055175781, loss_id 0.23661541938781738, loss_D 0.023608384653925896\n",
      "epoch 0, loss_GAN 0.006074660923331976 0.0022572719026356936, loss_cycle 4.84504508972168, loss_id 0.2138475924730301, loss_D 0.014182504266500473\n",
      "epoch 0, loss_GAN 0.004745012614876032 0.004211398307234049, loss_cycle 6.461219787597656, loss_id 0.3978475332260132, loss_D 0.015493378974497318\n",
      "epoch 0, loss_GAN 0.002634988399222493 0.005517180543392897, loss_cycle 6.740182876586914, loss_id 0.34742680191993713, loss_D 0.013733824715018272\n",
      "epoch 0, loss_GAN 0.003466191003099084 0.0036984975449740887, loss_cycle 6.173052787780762, loss_id 0.3133280277252197, loss_D 0.01320133451372385\n",
      "epoch 0, loss_GAN 0.0043205441907048225 0.0038354506250470877, loss_cycle 4.615221977233887, loss_id 0.20432768762111664, loss_D 0.015464240219444036\n",
      "epoch 0, loss_GAN 0.003697797888889909 0.004566642921417952, loss_cycle 7.216361999511719, loss_id 0.42546331882476807, loss_D 0.016784483566880226\n",
      "epoch 0, loss_GAN 0.009451495483517647 0.0032535239588469267, loss_cycle 6.300513744354248, loss_id 0.31650102138519287, loss_D 0.027311522513628006\n",
      "epoch 0, loss_GAN 0.0033869885373860598 0.003382172202691436, loss_cycle 7.223060131072998, loss_id 0.41105055809020996, loss_D 0.015274231787770987\n",
      "epoch 0, loss_GAN 0.009889449924230576 0.005447687581181526, loss_cycle 6.589077949523926, loss_id 0.26747018098831177, loss_D 0.023682549595832825\n",
      "epoch 0, loss_GAN 0.004492558538913727 0.0052645266987383366, loss_cycle 4.6216254234313965, loss_id 0.27886074781417847, loss_D 0.013897100929170847\n",
      "epoch 0, loss_GAN 0.003242889419198036 0.006164523307234049, loss_cycle 9.971858978271484, loss_id 0.5510603189468384, loss_D 0.021227856166660786\n",
      "epoch 0, loss_GAN 0.00784511398524046 0.004444871563464403, loss_cycle 5.434479713439941, loss_id 0.2509814500808716, loss_D 0.022314421832561493\n",
      "epoch 0, loss_GAN 0.004686241969466209 0.003509408561512828, loss_cycle 5.413957118988037, loss_id 0.29810455441474915, loss_D 0.014325829222798347\n",
      "epoch 0, loss_GAN 0.007314466871321201 0.003963172901421785, loss_cycle 5.240740776062012, loss_id 0.249971404671669, loss_D 0.02356355218216777\n",
      "epoch 0, loss_GAN 0.007008469197899103 0.007888215593993664, loss_cycle 6.377157688140869, loss_id 0.3264545798301697, loss_D 0.025991996750235558\n",
      "epoch 0, loss_GAN 0.019490670412778854 0.008462012745440006, loss_cycle 5.773805618286133, loss_id 0.25003179907798767, loss_D 0.04847347363829613\n",
      "epoch 0, loss_GAN 0.028934378176927567 0.017572777345776558, loss_cycle 6.795443534851074, loss_id 0.2992728352546692, loss_D 0.06160609424114227\n",
      "epoch 0, loss_GAN 0.04789944365620613 0.03693880885839462, loss_cycle 6.610991954803467, loss_id 0.2772443890571594, loss_D 0.10506346821784973\n",
      "epoch 0, loss_GAN 0.1234525665640831 0.10476664453744888, loss_cycle 6.320281028747559, loss_id 0.2888471484184265, loss_D 0.22857683897018433\n",
      "epoch 0, loss_GAN 0.35350674390792847 0.2920221984386444, loss_cycle 8.906423568725586, loss_id 0.37703531980514526, loss_D 0.671872615814209\n",
      "epoch 0, loss_GAN 1.201654076576233 0.8049073815345764, loss_cycle 8.961749076843262, loss_id 0.36560386419296265, loss_D 1.9962782263755798\n",
      "epoch 0, loss_GAN 4.034028053283691 2.3400611877441406, loss_cycle 9.979205131530762, loss_id 0.46712324023246765, loss_D 6.1090192794799805\n",
      "epoch 0, loss_GAN 11.004355430603027 6.602750778198242, loss_cycle 9.615330696105957, loss_id 0.38054144382476807, loss_D 16.656482696533203\n",
      "epoch 0, loss_GAN 23.06048011779785 15.043014526367188, loss_cycle 8.513325691223145, loss_id 0.379834920167923, loss_D 36.503132820129395\n",
      "epoch 0, loss_GAN 43.38361740112305 28.66431427001953, loss_cycle 9.847285270690918, loss_id 0.4564359188079834, loss_D 68.86484336853027\n",
      "epoch 0, loss_GAN 74.30982208251953 52.69139099121094, loss_cycle 7.4520134925842285, loss_id 0.38574451208114624, loss_D 123.52294921875\n",
      "epoch 0, loss_GAN 120.36831665039062 86.00116729736328, loss_cycle 11.04212760925293, loss_id 0.43248435854911804, loss_D 195.73821258544922\n",
      "epoch 0, loss_GAN 162.31396484375 118.09732818603516, loss_cycle 11.866990089416504, loss_id 0.4300103485584259, loss_D 261.4144287109375\n",
      "epoch 0, loss_GAN 187.65072631835938 134.5419158935547, loss_cycle 10.050413131713867, loss_id 0.45072734355926514, loss_D 298.8223419189453\n",
      "epoch 0, loss_GAN 236.5567169189453 176.47938537597656, loss_cycle 7.676024436950684, loss_id 0.5145174264907837, loss_D 400.34083557128906\n",
      "epoch 0, loss_GAN 250.7268829345703 212.69943237304688, loss_cycle 10.434024810791016, loss_id 0.6476861238479614, loss_D 442.3866882324219\n",
      "epoch 0, loss_GAN 301.8389587402344 245.2656707763672, loss_cycle 9.351189613342285, loss_id 0.5162378549575806, loss_D 503.0951232910156\n",
      "epoch 0, loss_GAN 323.3897705078125 262.77777099609375, loss_cycle 10.796125411987305, loss_id 0.6142079830169678, loss_D 563.1233978271484\n",
      "epoch 0, loss_GAN 368.1527099609375 322.0682373046875, loss_cycle 11.383054733276367, loss_id 0.5829669237136841, loss_D 642.6070556640625\n",
      "epoch 0, loss_GAN 418.6067810058594 363.4931945800781, loss_cycle 12.11566162109375, loss_id 0.6062531471252441, loss_D 754.4801635742188\n",
      "epoch 0, loss_GAN 489.59393310546875 393.1674499511719, loss_cycle 11.901141166687012, loss_id 0.6898764967918396, loss_D 844.8702392578125\n",
      "epoch 0, loss_GAN 497.47625732421875 459.1547546386719, loss_cycle 10.613821029663086, loss_id 0.5182074308395386, loss_D 921.5469360351562\n",
      "epoch 0, loss_GAN 602.41943359375 521.6326293945312, loss_cycle 15.94999885559082, loss_id 0.6579849720001221, loss_D 1057.9581909179688\n",
      "epoch 0, loss_GAN 657.6550903320312 322.4071044921875, loss_cycle 10.377959251403809, loss_id 0.5055853128433228, loss_D 1039.1184387207031\n",
      "epoch 0, loss_GAN 525.693359375 523.6638793945312, loss_cycle 10.110746383666992, loss_id 0.5845285058021545, loss_D 1101.2989501953125\n",
      "epoch 0, loss_GAN 749.1693115234375 586.505859375, loss_cycle 11.482988357543945, loss_id 0.6787436008453369, loss_D 1292.6528930664062\n",
      "epoch 0, loss_GAN 718.1189575195312 654.8784790039062, loss_cycle 9.936247825622559, loss_id 0.6862112283706665, loss_D 1336.237548828125\n",
      "epoch 0, loss_GAN 876.29638671875 755.6260375976562, loss_cycle 12.822282791137695, loss_id 0.708979606628418, loss_D 1575.0283203125\n",
      "epoch 0, loss_GAN 918.1458129882812 812.6063842773438, loss_cycle 14.359731674194336, loss_id 0.6727737188339233, loss_D 1692.6372680664062\n",
      "epoch 0, loss_GAN 1044.219482421875 891.216064453125, loss_cycle 11.214439392089844, loss_id 0.5791566371917725, loss_D 1885.57763671875\n",
      "epoch 0, loss_GAN 1141.3050537109375 947.218994140625, loss_cycle 13.417572975158691, loss_id 0.7034101486206055, loss_D 2132.6398315429688\n",
      "epoch 0, loss_GAN 1267.3834228515625 1033.3248291015625, loss_cycle 14.200265884399414, loss_id 0.723564863204956, loss_D 2202.86376953125\n",
      "epoch 0, loss_GAN 1376.156982421875 1128.0633544921875, loss_cycle 12.912211418151855, loss_id 0.6660389304161072, loss_D 2321.251708984375\n",
      "epoch 0, loss_GAN 1385.892822265625 1091.183349609375, loss_cycle 13.764886856079102, loss_id 0.5980172157287598, loss_D 2466.031005859375\n",
      "epoch 0, loss_GAN 1361.1207275390625 1453.5848388671875, loss_cycle 13.870844841003418, loss_id 0.7091076374053955, loss_D 2659.4893798828125\n",
      "epoch 0, loss_GAN 1641.8663330078125 1410.66943359375, loss_cycle 15.835807800292969, loss_id 0.6642329096794128, loss_D 2984.55517578125\n",
      "epoch 0, loss_GAN 1642.9755859375 1696.114501953125, loss_cycle 14.656329154968262, loss_id 0.6901154518127441, loss_D 3156.609375\n",
      "epoch 0, loss_GAN 1837.292236328125 1809.9893798828125, loss_cycle 15.759812355041504, loss_id 0.8749014139175415, loss_D 3439.349609375\n",
      "epoch 0, loss_GAN 1852.8697509765625 1793.5648193359375, loss_cycle 14.583066940307617, loss_id 0.6708564162254333, loss_D 3533.233154296875\n",
      "epoch 0, loss_GAN 2038.5830078125 2191.37744140625, loss_cycle 15.358274459838867, loss_id 0.8014093041419983, loss_D 3808.684814453125\n",
      "epoch 0, loss_GAN 2216.836181640625 2100.904296875, loss_cycle 19.22356605529785, loss_id 0.7380877733230591, loss_D 4030.0367431640625\n",
      "epoch 0, loss_GAN 2283.4853515625 2317.148681640625, loss_cycle 18.124649047851562, loss_id 0.7934824824333191, loss_D 4259.54736328125\n",
      "epoch 0, loss_GAN 2411.692626953125 2111.38037109375, loss_cycle 15.712726593017578, loss_id 1.0040714740753174, loss_D 4328.69921875\n",
      "epoch 0, loss_GAN 2521.6181640625 2329.45361328125, loss_cycle 16.214906692504883, loss_id 0.7184151411056519, loss_D 4399.59130859375\n",
      "epoch 0, loss_GAN 2765.344970703125 2373.776611328125, loss_cycle 14.173078536987305, loss_id 0.7722514867782593, loss_D 4970.621826171875\n",
      "epoch 0, loss_GAN 2462.191162109375 2805.999755859375, loss_cycle 18.429433822631836, loss_id 0.7426674365997314, loss_D 4919.132080078125\n",
      "epoch 0, loss_GAN 3138.1591796875 2765.298583984375, loss_cycle 19.985559463500977, loss_id 0.9792789220809937, loss_D 5710.638916015625\n",
      "epoch 0, loss_GAN 3240.582275390625 2845.85107421875, loss_cycle 20.25200653076172, loss_id 0.7958078384399414, loss_D 5960.653564453125\n",
      "epoch 0, loss_GAN 3513.320556640625 2621.098876953125, loss_cycle 17.02751922607422, loss_id 0.8719382286071777, loss_D 5747.223388671875\n",
      "epoch 0, loss_GAN 3399.7734375 3063.53125, loss_cycle 17.3927059173584, loss_id 0.8270348906517029, loss_D 6094.255615234375\n",
      "epoch 0, loss_GAN 3737.980712890625 3309.55517578125, loss_cycle 17.725200653076172, loss_id 0.7643706798553467, loss_D 6578.834228515625\n",
      "epoch 0, loss_GAN 4040.643310546875 3317.699462890625, loss_cycle 21.52637481689453, loss_id 0.8678196668624878, loss_D 6846.39453125\n",
      "epoch 0, loss_GAN 3905.552978515625 4028.147216796875, loss_cycle 19.43574333190918, loss_id 0.9743548631668091, loss_D 7046.11767578125\n",
      "epoch 0, loss_GAN 4022.057373046875 3450.04345703125, loss_cycle 17.05933380126953, loss_id 0.859772801399231, loss_D 7387.8701171875\n",
      "epoch 0, loss_GAN 4748.13671875 4030.775634765625, loss_cycle 20.766145706176758, loss_id 0.853541374206543, loss_D 8384.4306640625\n",
      "epoch 0, loss_GAN 3929.316650390625 4240.40234375, loss_cycle 19.413928985595703, loss_id 0.8721247911453247, loss_D 7834.580810546875\n",
      "epoch 0, loss_GAN 4832.9736328125 4680.56103515625, loss_cycle 18.021072387695312, loss_id 0.8040043711662292, loss_D 8943.26806640625\n",
      "epoch 0, loss_GAN 5155.5751953125 4897.25634765625, loss_cycle 16.395626068115234, loss_id 0.9023001790046692, loss_D 9683.95849609375\n",
      "epoch 0, loss_GAN 5546.80908203125 5308.35693359375, loss_cycle 12.410560607910156, loss_id 0.7033355832099915, loss_D 9927.5087890625\n",
      "epoch 0, loss_GAN 5364.5869140625 5512.91015625, loss_cycle 20.694055557250977, loss_id 1.000701665878296, loss_D 10385.43798828125\n",
      "epoch 0, loss_GAN 5903.84521484375 5225.87353515625, loss_cycle 16.912067413330078, loss_id 0.8281162977218628, loss_D 10563.1611328125\n",
      "epoch 0, loss_GAN 5928.2021484375 5815.9052734375, loss_cycle 17.97773551940918, loss_id 0.9165464639663696, loss_D 11249.04052734375\n",
      "epoch 0, loss_GAN 6329.4248046875 6620.6396484375, loss_cycle 18.233501434326172, loss_id 0.8895660638809204, loss_D 12413.6552734375\n",
      "epoch 0, loss_GAN 4964.80126953125 6687.30224609375, loss_cycle 16.494632720947266, loss_id 0.7718548774719238, loss_D 11426.31787109375\n",
      "epoch 0, loss_GAN 6112.68896484375 6376.44970703125, loss_cycle 18.424837112426758, loss_id 0.8752989172935486, loss_D 12280.34130859375\n",
      "epoch 0, loss_GAN 6064.2998046875 7518.10791015625, loss_cycle 16.739484786987305, loss_id 0.9258225560188293, loss_D 13012.494140625\n",
      "epoch 0, loss_GAN 6891.93603515625 7143.6708984375, loss_cycle 16.71692657470703, loss_id 0.8414170742034912, loss_D 13767.3857421875\n",
      "epoch 0, loss_GAN 6940.54248046875 7428.78271484375, loss_cycle 15.944003105163574, loss_id 0.8572083711624146, loss_D 14185.15869140625\n",
      "epoch 0, loss_GAN 7024.8310546875 8433.1572265625, loss_cycle 15.830391883850098, loss_id 0.9368730783462524, loss_D 15147.1240234375\n",
      "epoch 0, loss_GAN 7535.01025390625 8101.32470703125, loss_cycle 12.760534286499023, loss_id 0.6847509145736694, loss_D 15373.69091796875\n",
      "epoch 0, loss_GAN 7659.0546875 8574.908203125, loss_cycle 16.6750545501709, loss_id 0.8487266898155212, loss_D 14668.248046875\n",
      "epoch 0, loss_GAN 8347.2548828125 8012.81884765625, loss_cycle 13.436185836791992, loss_id 0.7122290730476379, loss_D 15989.58251953125\n",
      "epoch 0, loss_GAN 7998.6474609375 10013.1083984375, loss_cycle 13.601058959960938, loss_id 0.6173363924026489, loss_D 17381.083984375\n",
      "epoch 0, loss_GAN 8481.5576171875 9903.8671875, loss_cycle 15.639887809753418, loss_id 0.8460254073143005, loss_D 17523.35595703125\n",
      "epoch 0, loss_GAN 9401.75390625 10826.529296875, loss_cycle 16.5467472076416, loss_id 0.7818162441253662, loss_D 19449.30859375\n",
      "epoch 0, loss_GAN 10099.1669921875 10302.271484375, loss_cycle 17.63486671447754, loss_id 0.8916428685188293, loss_D 19084.76953125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m CycleGAN(Generator, Discriminator, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m), lambda_cyc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, lambda_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, gan_loss_type\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      2\u001b[0m lr_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.0002\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_policy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_decay_iters\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m50\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_count\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs_decay\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m} \u001b[38;5;66;03m# 100 epoch동안 그대로, 100 epoch 동안 decay\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m201\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[97], line 142\u001b[0m, in \u001b[0;36mCycleGAN.train\u001b[0;34m(self, dataloader, num_epochs, lr_args)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# TODO - logging\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cnt \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 142\u001b[0m     log_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_G\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss_G\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    143\u001b[0m     log_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_D\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss_GAN_D_A\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m loss_GAN_D_B\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loss_GAN \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg1\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg2\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loss_cycle \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_cycle\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loss_id \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_id\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loss_D \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_GAN_D_A\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mloss_GAN_D_B\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CycleGAN(Generator, Discriminator, 64, 64, 3, (3, 256, 256), lambda_cyc=10, lambda_id=0.5, gan_loss_type=nn.MSELoss, device=device)\n",
    "lr_args = {'lr': 0.0002, 'lr_policy': 'linear', 'lr_decay_iters': 50, 'epoch_count': 1, 'n_epochs': 100, 'n_epochs_decay': 100} # 100 epoch동안 그대로, 100 epoch 동안 decay\n",
    "\n",
    "model.train(train_dataloader, 201, lr_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear\n",
      "LeakyReLU\n",
      "Linear\n",
      "BatchNorm1d\n",
      "LeakyReLU\n",
      "Linear\n",
      "BatchNorm1d\n",
      "LeakyReLU\n",
      "Linear\n",
      "BatchNorm1d\n",
      "LeakyReLU\n",
      "Linear\n",
      "Tanh\n",
      "Sequential\n",
      "Generator\n",
      "Linear\n",
      "LeakyReLU\n",
      "Linear\n",
      "LeakyReLU\n",
      "Linear\n",
      "Sigmoid\n",
      "Sequential\n",
      "Discriminator\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nApplies fn recursively to every submodule (as returned by .children()) as well as self. \\nTypical use includes initializing the parameters of a model (see also torch.nn.init).\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_model(model):\n",
    "    classname = model.__class__.__name__ # module name?\n",
    "    print(classname)\n",
    "    # fc layer\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(model.bias.data, 0)\n",
    "    # batchnorm\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(model.bias.data, 0)\n",
    "\n",
    "\n",
    "model_gen.apply(initialize_model)\n",
    "model_dis.apply(initialize_model)\n",
    "'''\n",
    "Applies fn recursively to every submodule (as returned by .children()) as well as self. \n",
    "Typical use includes initializing the parameters of a model (see also torch.nn.init).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn = nn.BCELoss()\n",
    "# - (y_n * log(x_n) + (1 - y_n) * log(1 - x_n))\n",
    "# y_n에 real / fake label, x_n에 discriminator의 output을 넣어서 의도한 loss를 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim # for optimization\n",
    "\n",
    "lr = 2e-4\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "opt_D = optim.Adam(model_dis.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "opt_G = optim.Adam(model_gen.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = 1\n",
    "fake = 0\n",
    "nz = 100\n",
    "num_epoch = 100\n",
    "loss_log = {'gen': [], 'dis': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, G_Loss: 2.248571, D_Loss: 0.343581, time: 0.13 min\n",
      "Epoch: 1, G_Loss: 1.373024, D_Loss: 0.184527, time: 0.27 min\n",
      "Epoch: 1, G_Loss: 1.489920, D_Loss: 0.439714, time: 0.41 min\n",
      "Epoch: 2, G_Loss: 2.860862, D_Loss: 0.482628, time: 0.55 min\n",
      "Epoch: 2, G_Loss: 2.048623, D_Loss: 0.299608, time: 0.68 min\n",
      "Epoch: 3, G_Loss: 3.279032, D_Loss: 0.380393, time: 0.82 min\n",
      "Epoch: 3, G_Loss: 2.515978, D_Loss: 0.238160, time: 0.96 min\n",
      "Epoch: 4, G_Loss: 2.053371, D_Loss: 0.187470, time: 1.10 min\n",
      "Epoch: 4, G_Loss: 0.770059, D_Loss: 0.379480, time: 1.24 min\n",
      "Epoch: 5, G_Loss: 3.380693, D_Loss: 0.547626, time: 1.38 min\n",
      "Epoch: 5, G_Loss: 2.982160, D_Loss: 0.173397, time: 1.52 min\n",
      "Epoch: 6, G_Loss: 2.263862, D_Loss: 0.158739, time: 1.66 min\n",
      "Epoch: 6, G_Loss: 1.545429, D_Loss: 0.268927, time: 1.79 min\n",
      "Epoch: 7, G_Loss: 3.167553, D_Loss: 0.144705, time: 1.93 min\n",
      "Epoch: 7, G_Loss: 5.774007, D_Loss: 0.742368, time: 2.07 min\n",
      "Epoch: 8, G_Loss: 2.708421, D_Loss: 0.273394, time: 2.21 min\n",
      "Epoch: 9, G_Loss: 1.409322, D_Loss: 0.195033, time: 2.35 min\n",
      "Epoch: 9, G_Loss: 2.269504, D_Loss: 0.137708, time: 2.48 min\n",
      "Epoch: 10, G_Loss: 3.342292, D_Loss: 0.097553, time: 2.62 min\n",
      "Epoch: 10, G_Loss: 1.457187, D_Loss: 0.165466, time: 2.76 min\n",
      "Epoch: 11, G_Loss: 2.925528, D_Loss: 0.148387, time: 2.90 min\n",
      "Epoch: 11, G_Loss: 1.857540, D_Loss: 0.181615, time: 3.04 min\n",
      "Epoch: 12, G_Loss: 2.829149, D_Loss: 0.159143, time: 3.18 min\n",
      "Epoch: 12, G_Loss: 1.298719, D_Loss: 0.322791, time: 3.32 min\n",
      "Epoch: 13, G_Loss: 1.869215, D_Loss: 0.301425, time: 3.46 min\n",
      "Epoch: 13, G_Loss: 1.828438, D_Loss: 0.166112, time: 3.59 min\n",
      "Epoch: 14, G_Loss: 2.383764, D_Loss: 0.251409, time: 3.73 min\n",
      "Epoch: 14, G_Loss: 3.703023, D_Loss: 0.251299, time: 3.87 min\n",
      "Epoch: 15, G_Loss: 2.871870, D_Loss: 0.117701, time: 4.01 min\n",
      "Epoch: 15, G_Loss: 3.419187, D_Loss: 0.115779, time: 4.15 min\n",
      "Epoch: 16, G_Loss: 0.917067, D_Loss: 0.404452, time: 4.29 min\n",
      "Epoch: 17, G_Loss: 2.382244, D_Loss: 0.156451, time: 4.43 min\n",
      "Epoch: 17, G_Loss: 3.860205, D_Loss: 0.394466, time: 4.57 min\n",
      "Epoch: 18, G_Loss: 2.338864, D_Loss: 0.090870, time: 4.71 min\n",
      "Epoch: 18, G_Loss: 4.159131, D_Loss: 0.185828, time: 4.84 min\n",
      "Epoch: 19, G_Loss: 3.893356, D_Loss: 0.161192, time: 4.98 min\n",
      "Epoch: 19, G_Loss: 4.090775, D_Loss: 0.108560, time: 5.12 min\n",
      "Epoch: 20, G_Loss: 1.510046, D_Loss: 0.162995, time: 5.26 min\n",
      "Epoch: 20, G_Loss: 1.734296, D_Loss: 0.139371, time: 5.40 min\n",
      "Epoch: 21, G_Loss: 2.606822, D_Loss: 0.073908, time: 5.54 min\n",
      "Epoch: 21, G_Loss: 2.030457, D_Loss: 0.189924, time: 5.68 min\n",
      "Epoch: 22, G_Loss: 3.434124, D_Loss: 0.089316, time: 5.82 min\n",
      "Epoch: 22, G_Loss: 1.333333, D_Loss: 0.411431, time: 5.95 min\n",
      "Epoch: 23, G_Loss: 2.669775, D_Loss: 0.223223, time: 6.09 min\n",
      "Epoch: 23, G_Loss: 4.533232, D_Loss: 0.201555, time: 6.23 min\n",
      "Epoch: 24, G_Loss: 3.745903, D_Loss: 0.253310, time: 6.37 min\n",
      "Epoch: 25, G_Loss: 2.639678, D_Loss: 0.081808, time: 6.50 min\n",
      "Epoch: 25, G_Loss: 4.149884, D_Loss: 0.146562, time: 6.64 min\n",
      "Epoch: 26, G_Loss: 3.460778, D_Loss: 0.142302, time: 6.77 min\n",
      "Epoch: 26, G_Loss: 3.481818, D_Loss: 0.151319, time: 6.91 min\n",
      "Epoch: 27, G_Loss: 1.585244, D_Loss: 0.358839, time: 7.04 min\n",
      "Epoch: 27, G_Loss: 4.074637, D_Loss: 0.274060, time: 7.18 min\n",
      "Epoch: 28, G_Loss: 3.077833, D_Loss: 0.168967, time: 7.32 min\n",
      "Epoch: 28, G_Loss: 2.407449, D_Loss: 0.135662, time: 7.46 min\n",
      "Epoch: 29, G_Loss: 3.797337, D_Loss: 0.094165, time: 7.59 min\n",
      "Epoch: 29, G_Loss: 1.998558, D_Loss: 0.317791, time: 7.73 min\n",
      "Epoch: 30, G_Loss: 4.366139, D_Loss: 0.265038, time: 7.86 min\n",
      "Epoch: 30, G_Loss: 2.705001, D_Loss: 0.243314, time: 8.00 min\n",
      "Epoch: 31, G_Loss: 4.640164, D_Loss: 0.301440, time: 8.13 min\n",
      "Epoch: 31, G_Loss: 3.250362, D_Loss: 0.108264, time: 8.27 min\n",
      "Epoch: 32, G_Loss: 1.654365, D_Loss: 0.270553, time: 8.40 min\n",
      "Epoch: 33, G_Loss: 6.431348, D_Loss: 0.490120, time: 8.54 min\n",
      "Epoch: 33, G_Loss: 1.859636, D_Loss: 0.235218, time: 8.68 min\n",
      "Epoch: 34, G_Loss: 3.124796, D_Loss: 0.098887, time: 8.81 min\n",
      "Epoch: 34, G_Loss: 2.239579, D_Loss: 0.153009, time: 8.95 min\n",
      "Epoch: 35, G_Loss: 3.088968, D_Loss: 0.294162, time: 9.08 min\n",
      "Epoch: 35, G_Loss: 4.782725, D_Loss: 0.085192, time: 9.22 min\n",
      "Epoch: 36, G_Loss: 3.654551, D_Loss: 0.108315, time: 9.35 min\n",
      "Epoch: 36, G_Loss: 1.479487, D_Loss: 0.269056, time: 9.49 min\n",
      "Epoch: 37, G_Loss: 2.782502, D_Loss: 0.193491, time: 9.62 min\n",
      "Epoch: 37, G_Loss: 3.205191, D_Loss: 0.055812, time: 9.76 min\n",
      "Epoch: 38, G_Loss: 3.004481, D_Loss: 0.203002, time: 9.90 min\n",
      "Epoch: 38, G_Loss: 2.042407, D_Loss: 0.150580, time: 10.03 min\n",
      "Epoch: 39, G_Loss: 2.066894, D_Loss: 0.233076, time: 10.17 min\n",
      "Epoch: 39, G_Loss: 2.856535, D_Loss: 0.152573, time: 10.30 min\n",
      "Epoch: 40, G_Loss: 2.662789, D_Loss: 0.226075, time: 10.44 min\n",
      "Epoch: 41, G_Loss: 3.014780, D_Loss: 0.200307, time: 10.57 min\n",
      "Epoch: 41, G_Loss: 2.087982, D_Loss: 0.245350, time: 10.71 min\n",
      "Epoch: 42, G_Loss: 1.994336, D_Loss: 0.192428, time: 10.84 min\n",
      "Epoch: 42, G_Loss: 2.748523, D_Loss: 0.112959, time: 10.98 min\n",
      "Epoch: 43, G_Loss: 2.546944, D_Loss: 0.120583, time: 11.12 min\n",
      "Epoch: 43, G_Loss: 3.638339, D_Loss: 0.111324, time: 11.26 min\n",
      "Epoch: 44, G_Loss: 2.827392, D_Loss: 0.051477, time: 11.39 min\n",
      "Epoch: 44, G_Loss: 2.952543, D_Loss: 0.321841, time: 11.53 min\n",
      "Epoch: 45, G_Loss: 3.332393, D_Loss: 0.315787, time: 11.68 min\n",
      "Epoch: 45, G_Loss: 2.017733, D_Loss: 0.168271, time: 11.82 min\n",
      "Epoch: 46, G_Loss: 3.621490, D_Loss: 0.108134, time: 11.95 min\n",
      "Epoch: 46, G_Loss: 3.128462, D_Loss: 0.132803, time: 12.09 min\n",
      "Epoch: 47, G_Loss: 3.037019, D_Loss: 0.194320, time: 12.22 min\n",
      "Epoch: 47, G_Loss: 3.082187, D_Loss: 0.290906, time: 12.35 min\n",
      "Epoch: 48, G_Loss: 2.269946, D_Loss: 0.130783, time: 12.49 min\n",
      "Epoch: 49, G_Loss: 3.168049, D_Loss: 0.167313, time: 12.62 min\n",
      "Epoch: 49, G_Loss: 1.945098, D_Loss: 0.318842, time: 12.75 min\n",
      "Epoch: 50, G_Loss: 3.422561, D_Loss: 0.110909, time: 12.89 min\n",
      "Epoch: 50, G_Loss: 4.134887, D_Loss: 0.134447, time: 13.02 min\n",
      "Epoch: 51, G_Loss: 2.977668, D_Loss: 0.221551, time: 13.16 min\n",
      "Epoch: 51, G_Loss: 4.702189, D_Loss: 0.120548, time: 13.29 min\n",
      "Epoch: 52, G_Loss: 4.180346, D_Loss: 0.128090, time: 13.43 min\n",
      "Epoch: 52, G_Loss: 3.777678, D_Loss: 0.101712, time: 13.56 min\n",
      "Epoch: 53, G_Loss: 2.952598, D_Loss: 0.111374, time: 13.70 min\n",
      "Epoch: 53, G_Loss: 2.868429, D_Loss: 0.246794, time: 13.83 min\n",
      "Epoch: 54, G_Loss: 3.027099, D_Loss: 0.224755, time: 13.97 min\n",
      "Epoch: 54, G_Loss: 3.266628, D_Loss: 0.123914, time: 14.10 min\n",
      "Epoch: 55, G_Loss: 4.224511, D_Loss: 0.131029, time: 14.24 min\n",
      "Epoch: 55, G_Loss: 4.728468, D_Loss: 0.363470, time: 14.38 min\n",
      "Epoch: 56, G_Loss: 2.077581, D_Loss: 0.256723, time: 14.52 min\n",
      "Epoch: 57, G_Loss: 3.657490, D_Loss: 0.294846, time: 14.66 min\n",
      "Epoch: 57, G_Loss: 3.823598, D_Loss: 0.168529, time: 14.80 min\n",
      "Epoch: 58, G_Loss: 2.861141, D_Loss: 0.151058, time: 14.94 min\n",
      "Epoch: 58, G_Loss: 2.761585, D_Loss: 0.203499, time: 15.08 min\n",
      "Epoch: 59, G_Loss: 3.386908, D_Loss: 0.212582, time: 15.21 min\n",
      "Epoch: 59, G_Loss: 2.909719, D_Loss: 0.220354, time: 15.35 min\n",
      "Epoch: 60, G_Loss: 1.733117, D_Loss: 0.211709, time: 15.49 min\n",
      "Epoch: 60, G_Loss: 2.495300, D_Loss: 0.304699, time: 15.63 min\n",
      "Epoch: 61, G_Loss: 1.573578, D_Loss: 0.293479, time: 15.77 min\n",
      "Epoch: 61, G_Loss: 3.160697, D_Loss: 0.182083, time: 15.90 min\n",
      "Epoch: 62, G_Loss: 3.579413, D_Loss: 0.164689, time: 16.04 min\n",
      "Epoch: 62, G_Loss: 3.322556, D_Loss: 0.142964, time: 16.18 min\n",
      "Epoch: 63, G_Loss: 1.894143, D_Loss: 0.201510, time: 16.32 min\n",
      "Epoch: 63, G_Loss: 3.096412, D_Loss: 0.191951, time: 16.46 min\n",
      "Epoch: 64, G_Loss: 2.497370, D_Loss: 0.105876, time: 16.59 min\n",
      "Epoch: 65, G_Loss: 2.524169, D_Loss: 0.203590, time: 16.73 min\n",
      "Epoch: 65, G_Loss: 3.133966, D_Loss: 0.284881, time: 16.87 min\n",
      "Epoch: 66, G_Loss: 3.212939, D_Loss: 0.251258, time: 17.01 min\n",
      "Epoch: 66, G_Loss: 3.513342, D_Loss: 0.101350, time: 17.14 min\n",
      "Epoch: 67, G_Loss: 3.882078, D_Loss: 0.153369, time: 17.28 min\n",
      "Epoch: 67, G_Loss: 2.736989, D_Loss: 0.198526, time: 17.41 min\n",
      "Epoch: 68, G_Loss: 3.285049, D_Loss: 0.154736, time: 17.55 min\n",
      "Epoch: 68, G_Loss: 2.813395, D_Loss: 0.528818, time: 17.69 min\n",
      "Epoch: 69, G_Loss: 3.144663, D_Loss: 0.143419, time: 17.82 min\n",
      "Epoch: 69, G_Loss: 4.815951, D_Loss: 0.131255, time: 17.96 min\n",
      "Epoch: 70, G_Loss: 2.745481, D_Loss: 0.193637, time: 18.10 min\n",
      "Epoch: 70, G_Loss: 2.352427, D_Loss: 0.076984, time: 18.24 min\n",
      "Epoch: 71, G_Loss: 4.562813, D_Loss: 0.230373, time: 18.38 min\n",
      "Epoch: 71, G_Loss: 2.136209, D_Loss: 0.173256, time: 18.52 min\n",
      "Epoch: 72, G_Loss: 3.867301, D_Loss: 0.070886, time: 18.65 min\n",
      "Epoch: 73, G_Loss: 3.372038, D_Loss: 0.068217, time: 18.79 min\n",
      "Epoch: 73, G_Loss: 3.033995, D_Loss: 0.174886, time: 18.93 min\n",
      "Epoch: 74, G_Loss: 3.764304, D_Loss: 0.188257, time: 19.07 min\n",
      "Epoch: 74, G_Loss: 3.417792, D_Loss: 0.104140, time: 19.21 min\n",
      "Epoch: 75, G_Loss: 2.155372, D_Loss: 0.255378, time: 19.35 min\n",
      "Epoch: 75, G_Loss: 2.688240, D_Loss: 0.216109, time: 19.49 min\n",
      "Epoch: 76, G_Loss: 2.111378, D_Loss: 0.186448, time: 19.63 min\n",
      "Epoch: 76, G_Loss: 2.972702, D_Loss: 0.233315, time: 19.77 min\n",
      "Epoch: 77, G_Loss: 3.269523, D_Loss: 0.084163, time: 19.90 min\n",
      "Epoch: 77, G_Loss: 2.869291, D_Loss: 0.084068, time: 20.04 min\n",
      "Epoch: 78, G_Loss: 3.117851, D_Loss: 0.240050, time: 20.18 min\n",
      "Epoch: 78, G_Loss: 1.974191, D_Loss: 0.235494, time: 20.32 min\n",
      "Epoch: 79, G_Loss: 3.117220, D_Loss: 0.081954, time: 20.46 min\n",
      "Epoch: 79, G_Loss: 3.383378, D_Loss: 0.162167, time: 20.60 min\n",
      "Epoch: 80, G_Loss: 1.992253, D_Loss: 0.174254, time: 20.74 min\n",
      "Epoch: 81, G_Loss: 2.061794, D_Loss: 0.157622, time: 20.88 min\n",
      "Epoch: 81, G_Loss: 2.710701, D_Loss: 0.211092, time: 21.02 min\n",
      "Epoch: 82, G_Loss: 3.478673, D_Loss: 0.131261, time: 21.15 min\n",
      "Epoch: 82, G_Loss: 2.668801, D_Loss: 0.156656, time: 21.29 min\n",
      "Epoch: 83, G_Loss: 3.561944, D_Loss: 0.258455, time: 21.43 min\n",
      "Epoch: 83, G_Loss: 4.413015, D_Loss: 0.213720, time: 21.57 min\n",
      "Epoch: 84, G_Loss: 3.004852, D_Loss: 0.127433, time: 21.71 min\n",
      "Epoch: 84, G_Loss: 2.261618, D_Loss: 0.219893, time: 21.85 min\n",
      "Epoch: 85, G_Loss: 1.294275, D_Loss: 0.401170, time: 21.98 min\n",
      "Epoch: 85, G_Loss: 2.716555, D_Loss: 0.326425, time: 22.12 min\n",
      "Epoch: 86, G_Loss: 1.645532, D_Loss: 0.293600, time: 22.26 min\n",
      "Epoch: 86, G_Loss: 2.282951, D_Loss: 0.388156, time: 22.40 min\n",
      "Epoch: 87, G_Loss: 2.713255, D_Loss: 0.376841, time: 22.54 min\n",
      "Epoch: 87, G_Loss: 3.375931, D_Loss: 0.199902, time: 22.67 min\n",
      "Epoch: 88, G_Loss: 3.284573, D_Loss: 0.205568, time: 22.81 min\n",
      "Epoch: 89, G_Loss: 3.883578, D_Loss: 0.238251, time: 22.95 min\n",
      "Epoch: 89, G_Loss: 3.595485, D_Loss: 0.463017, time: 23.08 min\n",
      "Epoch: 90, G_Loss: 2.707883, D_Loss: 0.158410, time: 23.22 min\n",
      "Epoch: 90, G_Loss: 2.383655, D_Loss: 0.210633, time: 23.36 min\n",
      "Epoch: 91, G_Loss: 2.651691, D_Loss: 0.241821, time: 23.50 min\n",
      "Epoch: 91, G_Loss: 3.247872, D_Loss: 0.148445, time: 23.63 min\n",
      "Epoch: 92, G_Loss: 2.525055, D_Loss: 0.074759, time: 23.77 min\n",
      "Epoch: 92, G_Loss: 3.820446, D_Loss: 0.198867, time: 23.92 min\n",
      "Epoch: 93, G_Loss: 2.515935, D_Loss: 0.176966, time: 24.05 min\n",
      "Epoch: 93, G_Loss: 2.626781, D_Loss: 0.081014, time: 24.18 min\n",
      "Epoch: 94, G_Loss: 4.043065, D_Loss: 0.162258, time: 24.31 min\n",
      "Epoch: 94, G_Loss: 2.840324, D_Loss: 0.208471, time: 24.44 min\n",
      "Epoch: 95, G_Loss: 3.685047, D_Loss: 0.088271, time: 24.57 min\n",
      "Epoch: 95, G_Loss: 3.443731, D_Loss: 0.241322, time: 24.70 min\n",
      "Epoch: 96, G_Loss: 2.709917, D_Loss: 0.129128, time: 24.83 min\n",
      "Epoch: 97, G_Loss: 2.512118, D_Loss: 0.209838, time: 24.96 min\n",
      "Epoch: 97, G_Loss: 2.883578, D_Loss: 0.236320, time: 25.09 min\n",
      "Epoch: 98, G_Loss: 5.484905, D_Loss: 0.166291, time: 25.21 min\n",
      "Epoch: 98, G_Loss: 2.282400, D_Loss: 0.134697, time: 25.34 min\n",
      "Epoch: 99, G_Loss: 5.802439, D_Loss: 0.259154, time: 25.47 min\n",
      "Epoch: 99, G_Loss: 3.117479, D_Loss: 0.168346, time: 25.60 min\n"
     ]
    }
   ],
   "source": [
    "batch_count = 0\n",
    "start_time = time.time()\n",
    "model_dis.train()\n",
    "model_gen.train()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for x_batch, y_batch in train_dataloader:\n",
    "        batch_size = len(x_batch)\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch_r = torch.ones((batch_size, 1)).to(device)\n",
    "        y_batch_f = torch.zeros((batch_size, 1)).to(device)\n",
    "        \n",
    "        # Generator step\n",
    "        model_gen.zero_grad()\n",
    "        noise = torch.randn(batch_size, nz, device=device)\n",
    "        output_gen = model_gen(noise)\n",
    "        output_dis = model_dis(output_gen)\n",
    "        loss_gen = loss_fcn(output_dis, y_batch_r) # maximize log(D(G(z))), 본래는 log(1 - D(G(z)))를 minimize긴 한데 충분한 변화가 아님\n",
    "        loss_gen.backward()\n",
    "        opt_G.step()\n",
    "        \n",
    "        # Discriminator step\n",
    "        model_dis.zero_grad()\n",
    "        output_dis_real = model_dis(x_batch)\n",
    "        output_dis_fake = model_dis(output_gen.clone().detach())\n",
    "        loss_real = loss_fcn(output_dis_real, y_batch_r) # maximize log(D(x))\n",
    "        loss_fake = loss_fcn(output_dis_fake, y_batch_f) # maximize 1 - log(D(G(z)))\n",
    "        loss_dis = (loss_real + loss_fake) / 2\n",
    "        loss_dis.backward()\n",
    "        opt_D.step()\n",
    "        \n",
    "        loss_log['gen'].append(loss_gen.item())\n",
    "        loss_log['dis'].append(loss_dis.item())\n",
    "        \n",
    "        batch_count += 1\n",
    "        if batch_count % 1000 == 0:\n",
    "            print('Epoch: %.0f, G_Loss: %.6f, D_Loss: %.6f, time: %.2f min' %(epoch, loss_gen.item(), loss_dis.item(), (time.time()-start_time)/60))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Loss Progress')\n",
    "plt.plot(loss_log['gen'], label='Gen. Loss')\n",
    "plt.plot(loss_log['dis'], label='Dis. Loss')\n",
    "plt.xlabel('batch count')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './models'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "torch.save(model_dis.state_dict(), save_path+'/discriminator.pt')\n",
    "torch.save(model_gen.state_dict(), save_path+\"/generator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxkAAAMWCAYAAACdtUsqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIfklEQVR4nO3de5SddXkv8JnMJRlyD7kQAiFNlYuAyP2OhUKVZau0lIseEWu1gKJoj5d61OM6LKm6rKXlUqQoKAQrAhZRyxFMAS8QRHEJyM1QQwKEQAwhl7lkMjPnDxZH63oeZt7425l3z3w+f37X5p3f7Hmf2fvJXvOldWhoaKgFAACgkAmjfQAAAGBssWQAAABFWTIAAICiLBkAAEBRlgwAAKAoSwYAAFCUJQMAACjKkgEAABRlyQAAAIpqH+kDW1tbG3mOppE9D/7H6aOrLs+/OaHOzAkMry5z0tJiVqi34WbFJxkAAEBRlgwAAKAoSwYAAFCUJQMAAChqxH/4zYvq9AdhAABQRz7JAAAAirJkAAAARVkyAACAoiwZAABAUZYMAACgKEsGAABQlCUDAAAoypIBAAAUZckAAACKsmQAAABFWTIAAICiLBkAAEBRlgwAAKAoSwYAAFCUJQMAACjKkgEAABRlyQAAAIpqH+0DjFd77rlnmB911FFhfsMNN4T5Cy+8EOZDQ0PbdjAg1dXVFeY9PT3b+SQwvAkTqv074uDgYINOAvWwcOHCMH/Na14T5nfccUeYb9y4Mcy99/rvfJIBAAAUZckAAACKsmQAAABFWTIAAICiLBkAAEBRrUMj/FP41tbWRp+lqWVNAx0dHWE+ceLEMO/v7690nczcuXPDPGuvuuWWW8J8ypQpYb527dpK52m0ujQ6mJNtkz1vr371q8N8xYoVYb5u3bowX7NmTZjvtttuYf7QQw+F+Y477hjm2ZxcfvnlYf7e9743zBvNnDSHXXbZJcxf8YpXhPnXvva1ML/++uvD/Nxzzw3zgYGBMJ88eXKYv+1tbwvzH//4x2F+xBFHhPlll10W5qOlLnPS0mJWhvPcc8+F+aRJk8I8+129ZcuWMO/s7Kx0np122inM3/SmN4X5V7/61TCfOXNmmK9atarSeRptuFnxSQYAAFCUJQMAACjKkgEAABRlyQAAAIqyZAAAAEW1j/YBms2uu+5a6fFf+tKXwvycc84J86xFKvsL/sHBwTA/9thjw/w973lPmGftJK997WvDvG7tUjSHBQsWhHnW8vTd7343zLOGkO7u7jD/3ve+F+bHHHNMmGeyxo9M1r5zxhlnhPmMGTMqXZ+x6WMf+1iY33zzzWE+a9asMM9apHp7e8N8w4YNYb7XXnuF+eGHHx7mWVtU1jp15ZVXhnl7e/wWZfPmzWHO2DV79uwwz+6RL37xi2F+3nnnhXnWIpW9x8rekx133HFh/o53vCPML7300jD/y7/8yzCvW7vUcHySAQAAFGXJAAAAirJkAAAARVkyAACAoiwZAABAUdqlKvrKV74S5h/+8IfDfKeddgrzH/3oR2H++OOPh/kll1wS5gceeGCYX3vttWE+YUK8V2YtPllbD7ycrPEja1v61Kc+FebZ/Zo1fjz88MNhnrWtvfWtbw3zUnbfffcwX7NmTaXrZG1amzZtqnwm6uNNb3pTmGftT1lrU19fX5ivX78+zD/0oQ+F+UEHHRTm9957b5i3traGedY+mJ2zas74k72n+fu///swz5pAH3zwwTBfsWJFpeu/+tWvDvOrr746zLPXsrvuuivMs6a3ZuOTDAAAoChLBgAAUJQlAwAAKMqSAQAAFGXJAAAAitIuVdGf/umfhvmWLVvCfGBgIMyXLl0a5vfdd1+YDw0NhfmcOXPCPGv3yVpLTjnllDDfvHlzmMPLyVpnsvanbE6yRo6tW7eG+ec+97kwf/bZZ8P81ltvDfO2trYwz7zyla8M82xuq9IiNTZlrwO/+MUvwvyWW24J86zR5l//9V/DPGs3fOqpp8L83e9+d5hnLW/f/va3w/yd73xnmMNw/uIv/iLMs/de2WvEqaeeGubf+973wry/vz/Mp0+fHubZa0d2zqxhbt26dWHebHySAQAAFGXJAAAAirJkAAAARVkyAACAoiwZAABAUdqlKurr6wvzrB0na9m5//77w/wP//APw/zf//3fw3zBggWVzjNjxowwz74vGitrosh+fs0iO3/WtlR1rrJWmy9/+cthnjWNZM9/1u7z4IMPhvny5cvDHF5O1vb35JNPhvmkSZPC/B/+4R/C/KCDDgrzu+++O8wnT54c5pnjjz8+zH/yk59Uug4MJ5uV7LUge+91++23h/lee+0V5tdcc02Yz58/v9J5Zs6cGeY9PT1hPlb4JAMAACjKkgEAABRlyQAAAIqyZAAAAEVZMgAAgKJah7K6l999YPKX+ryos7MzzCdOnBjmV199dZgfcsghYb5y5cowP/jgg0dwut/I2kOavV1qhLdxw5mTF2XPw9KlS8P8qKOOCvOOjo5KXzdrkcrOU/XntdNOO4X52rVrw7wu9+VL6nIec/Ly9tlnnzA//PDDw/ziiy8O8+x53rRpU5hPmzat0nVuuOGGMD/99NPDvFnUZU5aWszKcLq6uirl3/zmN8N8jz32CPMnnngizF/zmtcMf7jfMn369DDv7u6udJ26GW5WfJIBAAAUZckAAACKsmQAAABFWTIAAICiLBkAAEBR7SN9YNby0t/fX+wwddLW1hbmEybEe9nGjRvDvL09foqz62RmzZoV5mvWrAnzww47LMwnTZoU5s3eLkW9vP/97w/zY489tqFfN5vbrHUqkz2+WVqk6i5rzBmrz2P2/c6cOTPMf/7zn4d51deNTNZ009PTE+bXXnttmN97771FzkPOe68XZff+hg0bKl2nalvX1KlTw/yZZ54J8yOPPDLMs6bRZm+XGo5PMgAAgKIsGQAAQFGWDAAAoChLBgAAUJQlAwAAKGrE7VJjtcngnHPOCfNLL700zKs2E1T1jW98I8xPPfXUMK/axjI4OFj5TIwfWSNH1nDy6KOPhvnChQuLnSmSNYocfPDBYT5t2rQw//znP1/p647V9qPtrdmfx+x14PWvf32Y33TTTWHe2dlZ6kihxx57LMz333//StfJGnayVkXKGavvvf7mb/4mzL/whS+EeaPfe33rW98K8z//8z8Pc++9RsYnGQAAQFGWDAAAoChLBgAAUJQlAwAAKMqSAQAAFNU6NMI/kW/0X/aPlqxNp7e3N8zb20dcyPWysqd90qRJYZ6d88ADDwzzhx9+OMzXrVtX6TyZu+++O8wPP/zwStcppS5tNc0+J1mL1G677RbmjzzySJhn92spU6ZMCfOsBefP/uzPwjxr38ny1atXj+B0v/H000+H+c4771zpOqWYkzKyVqgZM2aEeXbfTJjQ2H/ny15PsvMfcMABYf7444+H+TPPPBPmW7duHcHpfuOXv/xlmL/yla+sdJ1S6jInLS3NPyvZ+bP3Ut3d3ZUeX1X2s504cWKYZ69l++23X5gvX748zEu991q2bFmYH3bYYZWuU8pw5/dJBgAAUJQlAwAAKMqSAQAAFGXJAAAAirJkAAAARZX5c/0mlv1lfNYKk7XaZM0Ht9xyS5i/853vDPOs3efBBx8M86ylJmvHmj59ephXNVotUjRW1rDxgx/8IMyz5o3+/v4wf/7558M8a0n79a9/HebZObP52bJlS5hfdNFFYZ617FQ1Wi1SjI4jjzyy0uOz+zL7/X322WeH+c033xzm2evSZz/72TDPzp+97r3iFa8I86pGq0WKxsveY2X5+vXrwzy7l7PXoOuuuy7MzzvvvErXv++++8J80aJFYd7X1xfmWfNcVaPVIrWtfJIBAAAUZckAAACKsmQAAABFWTIAAICiLBkAAEBR475danBwMMx32223StfJGg4GBgbCvLW1tdL1syaGCRPiPXHq1KmVrg8tLS0tV111VZjPmjUrzJ944okwf+Mb3xjmK1euDPMXXnghzLM5ydp3snlYt25dmN92221hXnVusxapp556Ksxpbll72re//e0w33HHHcN848aNYZ69nmRtVFVfT7IWtsmTJ4f5tGnTwrzq61LWCtfT0xPmjF1bt24N8zlz5lS6TnavZe/tqs5KJmuj6uzsLHL97JzZzNWVTzIAAICiLBkAAEBRlgwAAKAoSwYAAFCUJQMAACiqdWiEf6pe6i/yx6pSTQCzZ88O83POOSfMP/rRj4Z51hLSbM0EI1WX76tZ5uS6664L80MPPTTMs7a1vr6+MN99993DPGthylp2Vq1aFeZZs0fVlprx1mpjTqqZMmVKmHd3d4f5zJkzwzxrQ9u8eXOYZ+1SWWNOJmvqedWrXhXmZ511Vpi/+c1vrvR1m11d5qSlpXlmZbSUeu81d+7cMH/Xu94V5v/rf/2vMM9+Z9TpnippuO/LJxkAAEBRlgwAAKAoSwYAAFCUJQMAACjKkgEAABSlXaqiUs9D9rQvXrw4zC+++OIwz1p57rzzzjC/7LLLRnC65lOX5oZGz0mpJo2nn346zDs7O8M8a3k65ZRTwnzNmjVh3t/fH+bf+c53wvySSy4J8ze+8Y1h/uUvfznMs3kYb8bLnJRStV2qavvThAnV/p0vaw3MzvMXf/EXYb7//vuH+eWXXx7mL7zwQpivX78+zJtdXeakpaV5ZqXRGv3ea5999gnzT3/602GevcbdfvvtYX7ttdeO4HTNR7sUAACwXVkyAACAoiwZAABAUZYMAACgKEsGAABQlHapirI2kKqtIjvvvHOY/+IXvwjza665Jsx/9rOfhflFF10U5lOnTh3B6ZpPXdpAmmVODjvssDC/6667wryvry/Ms/adgYGBSuf54Ac/GOZ///d/H+bZ87zHHnuE+a9+9aswz+Y5O3+pdq/RUpdzNsucZDo6OsK8q6srzDds2FDk606cODHMP/e5z4X5X//1X4f5+973vjDPWt6yFrms9bDZ1WVOWlqaf1ZKqfreK3vedt999zD/yU9+EuZZY+H3v//9MP/Xf/3XMJ85c2aYNzvtUgAAwHZlyQAAAIqyZAAAAEVZMgAAgKIsGQAAQFHto32AbVW1cSH7C/i2trYwz9plqrZOTJo0KczvueeeMF+7dm2Y/9Vf/VWYr1y5Msx7e3tHcDrGukWLFoX5+eefH+bPPfdcmN93331hXrVFKvN3f/d3YZ61+GRtPf39/WGe/b6o2gpXp9YZysleB7L7b8uWLWFe9X6q6vjjjw/z97znPWH+/PPPh/lb3vKWMF+6dGmYP/rooyM4HeNBs7z3mjx5cpjffffdYb5+/fowf9vb3hbmjzzySJhv2rRp+MONIz7JAAAAirJkAAAARVkyAACAoiwZAABAUZYMAACgqDHXLpW1e8yePTvMsyaAqg0HEybE+1r2+KzF48wzzwzzvr6+ML/pppvC/B/+4R/CnPElu29uvfXWMD/mmGPC/AMf+ECR85x00klh/sQTT4T5rFmzwnzatGlhnrWqZXOoLYqXk83PAQccEOYPPvhgka87c+bMMM/aorJWwrlz51Z6/DPPPBPmK1asCHPGn6rvvbJ78IUXXgjzqu+92tvjt7HZ45ctWxbmJ554Ypj39PSE+c033xzml156aZiPVz7JAAAAirJkAAAARVkyAACAoiwZAABAUZYMAACgqKZtl8qaA7I2kLa2tkp51qBQ9Tzz588P87e+9a2Vrt/R0RHmGzdurHQdxpc1a9aE+WmnnVbpOg899FCYZ61qmfvvvz/M99577zDP5nDDhg1hPnny5DB/7rnnRnA6xqus0SZrkDnkkEPCfMcddwzz7Pd3Jms9PP7448M8a0/Mvq9FixaFedbOBi/J3utk9072Hitrhar63iu7x3fdddcw/5M/+ZNK1+/s7Azz9evXV7rOeOWTDAAAoChLBgAAUJQlAwAAKMqSAQAAFGXJAAAAimradqnBwcEi18maElasWBHmf/RHfxTm99xzT5hnrR9VW3myNpCsPQhaWlpali5dGuYHHXRQpetkzSFZS9W6devC/NZbb630dbM5z86TzS28nP7+/jDPmnEyWSvUeeedF+Y33HBDmP/Xf/1XmGctVdnrWNa8c9RRR4U5DKfR770ee+yxMM9aoX72s5+F+bRp08K86nuvXXbZJcw1e46MTzIAAICiLBkAAEBRlgwAAKAoSwYAAFCUJQMAACiqdSj7E//ffWBra6PPUsn06dPDvKenJ8z7+vqKfN3s6cqen5/+9Kdhvscee4T5jBkzwjxrCeFFI7yNG65uc9LV1RXm2f1Uak6qytp9sva0XXfdtZHHGbPMSaxqa1M2J9n3leVVX09WrlwZ5u3tcVHkggULwpyXV5c5aWmp36xkrU1Z499ovfe6//77w3zx4sVhnr2nLNWmNVYNNys+yQAAAIqyZAAAAEVZMgAAgKIsGQAAQFGWDAAAoKi4kmIUZH/Bf+2114b5ySefHOY77LBDpetfcMEFYf6pT30qzLOmhOzrZm1XVdtGml1nZ2eYb9myZTufpLll91PWSrZ58+YwnzCh2r8v/PCHPwzzH/zgB2H+0Y9+NMw3bdoU5rfeemuYn3rqqSM4Hfx3WVvZwQcfHOZ33313mGftbJl//Md/DPMLL7wwzJ988skw/8u//Mswv+WWW8I8+70wVo23189Gyt4bfeELXwjzt7/97WFe9b1XNhMf//jHwzy7x6dOnRrm2WvNeLt3Rvu9l08yAACAoiwZAABAUZYMAACgKEsGAABQlCUDAAAoqnVohH9Sn/1FPtRBXZohzAl1Zk5geHWZk5YWs0K9DTcrPskAAACKsmQAAABFWTIAAICiLBkAAEBRlgwAAKCo9tE+ADD2ZI0odWptAQAaxycZAABAUZYMAACgKEsGAABQlCUDAAAoypIBAAAUpV0KKE6LFACMbz7JAAAAirJkAAAARVkyAACAoiwZAABAUZYMAACgqNYhNTAAAEBBPskAAACKsmQAAABFWTIAAICiLBkAAEBRlgwAAKAoSwYAAFCUJQMAACjKkgEAABRlyQAAAIqyZAAAAEVZMgAAgKIsGQAAQFGWDAAAoChLBgAAUJQlAwAAKMqSAQAAFGXJAAAAirJkAAAARVkyAACAoiwZAABAUZYMAACgKEsGAABQlCUDAAAoypIBAAAUZckAAACKsmQAAABFWTIAAICiLBkAAEBRlgwAAKAoSwYAAFCUJQMAACjKkgEAABRlyQAAAIpqH+kDW1tbG3kO+L0MDQ2N9hFaWlrMCfVmTuolex7q8nMar+r0/JsV6my4WfFJBgAAUJQlAwAAKMqSAQAAFGXJAAAAihrxH34DAOXU6Q+MGZ8GBwfDfMIE/wbN789dBAAAFGXJAAAAirJkAAAARVkyAACAoiwZAABAUdqlAACaSKlWqLq1SGWNa62trdv5JPy27H4bTr3uLgAAoOlZMgAAgKIsGQAAQFGWDAAAoChLBgAAUJR2KQCAJlK3VqhSSrVIZS1VWT5Wn89Ssucnez7//3/XiMMAAADjlyUDAAAoypIBAAAUZckAAACKsmQAAABFaZcCgCa2++67h/lhhx0W5jfffHOYv/DCC2E+XIMMjJbs3izVUsXvxycZAABAUZYMAACgKEsGAABQlCUDAAAoypIBAAAUpV2qwTo7O8P8Qx/6UJjfeOONYf7www+H+aZNm8J81qxZYX7NNdeEeU9PT5gfeuihYX7IIYdUOg8AI7Nhw4Yw7+joCPNJkyaFeX9/f6XrZObNmxfmr3vd68I8ex2bPn16mK9evbrSeRi7qjaZlWqR6u3tDfNsthgZn2QAAABFWTIAAICiLBkAAEBRlgwAAKAoSwYAAFCUdqlCTjjhhDDPWps+/vGPh/mnPvWpMM9amx566KEw32+//cJ88uTJYX7aaaeF+cDAQJifccYZYb7LLruE+cc+9rEwBxiv5s+fX+nxV1xxRZife+65YZ61SGUNPoODg2F+3HHHhfm73/3uML/yyivD/MQTTwxz7VIMp1SLVEaLVGP4JAMAACjKkgEAABRlyQAAAIqyZAAAAEVZMgAAgKK0S1U0bdq0MM/apd773veGeWdnZ5hv2bIlzL/97W+H+eLFi8N82bJlYZ7JWqSyRofLL788zLN2kkx2/az9hOZw1llnhfnFF18c5u3to/OraMIE/87C6FmyZEmYZ+2D8+bNC/Of/OQnYf7444+H+YUXXhjm+++/f5hfc801YZ7Nzx133BHmGzduDHN4idf+scUrLAAAUJQlAwAAKMqSAQAAFGXJAAAAirJkAAAARWmXqqi3tzfMb7nlljA/+eSTw3zRokVhvnbt2jC/6qqrKp1n6dKlYZ61OWWtVlOnTq10nao0STSHe++9N8wPPPDAStepet9UvT/GalvZ7bffHubHHnvsdj4JJf3Zn/1ZmGe/j7MWwDvvvDPMs5bBrAVwxx13DPOs/a2vry/M//zP/zzMN2zYEObwkp/97GejfYT/JpuVUs2Ejb7+aBsb3wUAAFAblgwAAKAoSwYAAFCUJQMAACjKkgEAABTVOjTC2pWqrTBjteUl+4v/P/iDPwjza665Jsznz58f5p2dnWE+bdq0Sufp6uoK83/+538O8+uvvz7M77rrrjCvm7rcV6Vatxpt1apVYb5gwYIwH602se985zthfsABB4R51uaW3cdbt24N82wOm505qZe2trYwz1qksudt5syZYb548eIwz37f77zzzmGenXPKlClhnrUeNou6zElLy/iblaxZrdG/k7OWp8xYaX/6fQ03K54lAACgKEsGAABQlCUDAAAoypIBAAAUZckAAACKali71Hjzuc99LsxPP/30MN9ll13CPPtx9Pf3h3nW+pH9vLq7u8N8xowZYZ61nNRNXdpAxuqcZM0b2feb3Tdnn312mH/xi1/ctoP9jmwesvnJjNXmEHPSHCZOnBjmkyZNCvPrrrsuzPfbb78wX7lyZZgfeOCBYZ7dN1OnTg1z7VLljNVZqdrmlD0PpZ6f973vfWF+4YUXhnn2WjPeaJcCAAC2K0sGAABQlCUDAAAoypIBAAAUZckAAACKah/tAzSbY489Nsw/+MEPFrl+1pTQ0dER5lu2bAnzdevWhfmaNWvCvFlapMa7yy+/PMzPOuusItfPGj+ef/75MJ85c2aYt7ePzq+W7D7OGjDWrl0b5kcddVSY//CHP9y2g/HfZL/PqraANYusiSZrMdu4cWOYZ3NVtWEnaxPMXh8OPfTQMM9asJq9XYrRk81Eo19TDj744DDXIvX78UkGAABQlCUDAAAoypIBAAAUZckAAACKsmQAAABFtQ5ltSu/+8CK7RV1kzUWLFy4MMwfeOCBMJ8yZUqxM0WytptXvepVYZ41Lpx00klhvnr16jC/6aabhj1bnY3wNm64ZpmTrL3mscceC/PXve51YZ7dr6Nl6dKlYZ61wm3YsCHMs/adZmdOGitrebvsssvCvNHPwze/+c0wP/nkk8O86v2RtdE1u7rMSUtL889K9lzW7fvK7uWq56zb99Vow82KTzIAAICiLBkAAEBRlgwAAKAoSwYAAFCUJQMAAChq3LRLTZo0Kcz33nvvML/33nvDvNHPw8SJE8O8q6srzI844ogwz1qkli9fHuabNm0awel+Y9WqVWG+6667VrpOKXVpA2n2OWl2e+65Z5g/9NBDYb5ixYowX7x4cakj1Yo5aays7a+np6fS46vKfq7Z60lbW1uYH3DAAWH+6KOPhvm6desqnSezbNmyMD/ssMMqXaeUusxJS0vzzMr69evDPGvqy57jLM9mZWBgYNiz/bbsvWBvb2+l62TnzJpMxyrtUgAAwHZlyQAAAIqyZAAAAEVZMgAAgKIsGQAAQFHjpl1q6tSpYf6jH/0ozPfdd98w37p1a5hnzQqHHnpomD/55JNhnrV+HHnkkWH+p3/6p2F+3HHHhflrXvOaMB8cHAzzZlGXNpDRmpOsRaavry/Mzz333DC/5JJLip1pNGT3cXZ/ZPM2Vo33OWm07H5auXJlmGetgVmTzje/+c0wP/vss8M8+3k/8MADYb5gwYIwz36PTJ8+PcybXV3mpKVl7M5K1XapUi666KIwP++888K80c9/9v02y89duxQAALBdWTIAAICiLBkAAEBRlgwAAKAoSwYAAFBUXGExBv3hH/5hmN97771hfsUVV4T5lVdeGeZZ61TWypHJGgUGBgbCfPPmzWG+atWqMM/adyZMiPfN2bNnh/mzzz4b5oyO7D7Lfq7N3iI1adKkMM/mJ3seRkvWdrdx48btfBJKyn5PZ61Nmex+zX5/V22iqdq2lt2vMJyqjX/ZvZw9vurv9qrvyUpp9hapbVWvV14AAKDpWTIAAICiLBkAAEBRlgwAAKAoSwYAAFDUmGuXeuMb3xjm69evD/M3vOENYb5hw4Yw7+3tDfOOjo4wz9o6sqaBHXfcMcx/+ctfhvnq1avD/GMf+1iYZ7IGCC1SzS37uWb3ZdaOUzfd3d1hns1V3ey7775hftddd23nk1BHVe/j7PFZO+CXvvSlMP/EJz4R5p2dnZXOAy8ZrWa/qjM0efLkSo+v2vRWtUWqastWVaXavYbjkwwAAKAoSwYAAFCUJQMAACjKkgEAABRlyQAAAIpqHRrhn4xX/cv40XL22WeH+YoVK8L8gQceCPOnn346zKs+D8cff3yY33vvvWH+wQ9+MMwfeeSRMP/qV78a5tmPNWtEaHZ1aRVqljlpdqXu49FqPhkt5qReSj0P2c/1Fa94RZhfeOGFYb5x48Yw//73vx/mX/jCF0ZwuuZTlzlpaTErw8l+Vo1uTyrVItXshnvextcrLAAA0HCWDAAAoChLBgAAUJQlAwAAKMqSAQAAFDXm2qXa2trC/Mtf/nKYP/TQQ2H+6U9/ush59t577zC//fbbw3z69Olhfuihh4b5L37xizCfNm1amP/6178O82ZXlzaQZpmTsSprnbr11lvDvLe3N8xPOumkUkeqFXNSL1m7WdX2tIULF4b5/fffH+ZXX311mN93331hfvHFF4f51KlTR3C65lOXOWlpGbuzMm/evDBfvXp1peuUen6y65RqMly0aFGYr1y5ssj1R4t2KQAAYLuyZAAAAEVZMgAAgKIsGQAAQFGWDAAAoKj20T7Atpo4cWKY77nnnmH++c9/Psyzdo9SLrnkkjCfM2dOmD/33HNhPnv27Epfd+PGjZUeD9tDZ2dnmG/ZsqXSdSZPnlzp8a9//esrPb7Rvva1r4X56aefvp1PQktL9YaarFElazccGBiodJ1MV1dXmN9zzz1hnrUJvv3tbw/zVatWhXlPT8/wh4NA9h5rzZo1Yd7otqiqSr1HzGZ9rLaHvcQnGQAAQFGWDAAAoChLBgAAUJQlAwAAKMqSAQAAFNU6NMJ6i7r9BXxHR0eYZ+01F1xwQZh/5CMfCfO+vr5K59lvv/3C/Lzzzgvz//E//keYZ+ffa6+9wvzRRx8N86qtJc2uLt9v3eZkrHriiSfCfPr06WE+Y8aMBp6meZiTWNYgMzg4GOZz584N8w0bNoR5b29vpfNkLVXZ696VV14Z5m9+85srnWffffcN8+XLl4f5WFWXOWlpqd+sNFo2c1lDWzYToyU7f6ObTEfLcLMyNr9rAABg1FgyAACAoiwZAABAUZYMAACgKEsGAABQVNO2S2XnufDCC8P81FNPDfPZs2eHedbylMlabe67774w/4M/+IMw37hxY5i/6U1vCvM77rhj+MONA3VpA6nbnDS7SZMmhXl3d3eYZ80e7e3txc7UzMxJLDtP1sKUtT9ledXvN3t89rrx2GOPVTpPNifz5s0L87Vr14b5WFWXOWlpqd+sNNrb3/72MP/yl7+8Xc/ByGiXAgAAtitLBgAAUJQlAwAAKMqSAQAAFGXJAAAAimradqmnnnoqzHfeeecwz77NDRs2hPkpp5wS5k888USYP/LII2GePW8DAwNh/vzzz4f53Llzw7xOLRijqS7PQ93mpNllrTYPP/xwmB999NGNPE7TMyexUs9Ldp0nn3wyzI855pgw/8lPfhLmM2fODPMJE6r9e+Guu+4a5tk5x5u6zElLS/1mBX6bdikAAGC7smQAAABFWTIAAICiLBkAAEBRlgwAAKCopm2X6ujoqPT4vr6+MG/099XT0xPmzzzzTJgvXry4kccZs+rSBlK3OWl2g4ODlR5ftWVnvDEnsenTp4d5b29vpbyq7OeRPT8/+9nPwvyVr3xlmM+YMSPMs3ZDXlSXOWlpqd+s8PL6+/vDvOp71mahXQoAANiuLBkAAEBRlgwAAKAoSwYAAFCUJQMAACiqfbQP8JItW7aE+fz588N8zZo1Yd7eHn9LWUPDf/zHf4T59ddfH+ZXXXVVmD/++ONh/olPfCLMr7vuujCHbZG1MDV721I2t5s2bQrz97///WH+T//0T4VORDPI5mHJkiVhfsopp4R5V1dXpet//vOfD/PsdSBrqZo8eXKYd3d3h3k2J3VqSSqps7MzzLP3EbC9jNUWqW3V3O9AAACA2rFkAAAARVkyAACAoiwZAABAUZYMAACgqNahEdZPZO0VUAd1aVExJ9um1M/P8//yzAkMry5z0tJiVsar7B6s2/0w3Kz4JAMAACjKkgEAABRlyQAAAIqyZAAAAEVZMgAAgKLaR/sAAFljxsDAQJi3tbU18jgAMGrq1iK1rXySAQAAFGXJAAAAirJkAAAARVkyAACAoiwZAABAUdqlgNrSIgUAzcknGQAAQFGWDAAAoChLBgAAUJQlAwAAKMqSAQAAFNU6NDQ0NNqHAAAAxg6fZAAAAEVZMgAAgKIsGQAAQFGWDAAAoChLBgAAUJQlAwAAKMqSAQAAFGXJAAAAirJkAAAARVkyAACAoiwZAABAUZYMAACgKEsGAABQlCUDAAAoypIBAAAUZckAAACKsmQAAABFWTIAAICiLBkAAEBRlgwAAKAoSwYAAFCUJQMAACjKkgEAABRlyQAAAIqyZAAAAEVZMgAAgKIsGQAAQFGWDAAAoChLBgAAUJQlAwAAKMqSAQAAFGXJAAAAirJkAAAARbWP9IGtra2NPEfTyJ6HoaGh7XwSfltdnn9z8iJzUk91ef7NCXVWlzlpaTEr1Ntws+KTDAAAoChLBgAAUJQlAwAAKMqSAQAAFDXiP/zmRXX6gzCoK3MCUH+Dg4NhPmGCf4Pm9+cuAgAAirJkAAAARVkyAACAoiwZAABAUZYMAACgKO1SAABNpFQrVN1apLJmwtbW1u18En7bjBkztum/q9fdBQAAND1LBgAAUJQlAwAAKMqSAQAAFGXJAAAAimodyv6U/3cf6C/7qbER3sYNZ06oM3MCw6vLnLS0mJXhtLfHJalbtmypdJ3Ozs4w37p1a+UzjSfDzYpPMgAAgKIsGQAAQFGWDAAAoChLBgAAUJQlAwAAKCr+s3wabtGiRWG+//77h/mdd94Z5s8//3yY16kdA7bVPvvsE+ZHH310mF933XVhbk4Yy7IGoqrNRIODgyWOA9tN1iI1YYJ/Q68DPwUAAKAoSwYAAFCUJQMAACjKkgEAABRlyQAAAIpqHRphvUrVlorxZvXq1WE+efLkMJ86dWqYZ00JnZ2dlc6z0047hfnrX//6ML/hhhvCfMaMGWH+1FNPVTpPo9WlJcicvLyNGzeGeUdHR5hPnDgxzEvNyZw5c8L80EMPDfPvfe97YZ7N+bp16yqdp9HMSXNYuHBhmGf35Ze+9KUwX7ZsWZifcMIJYZ61S02ZMiXML7/88jD/1re+FebHHXdcmL/73e8O89G6X+syJy0t429WqjaclWqROvnkk8P8xhtvLHL9sWq4WfFJBgAAUJQlAwAAKMqSAQAAFGXJAAAAirJkAAAARbWP9gGazY477hjmWTvOpZdeGuYf+chHwjxrx8kaF7L8ta99bZifccYZYX7FFVeE+Rvf+MYwr1u7FPWSteNkTRTZ/fee97wnzKvOSfZ1szk5++yzwzxrGjnssMPCvG7tUjSHCy64IMxvvvnmMN9hhx3CPGuR6u/vD/Os/S1rtdprr73C/K1vfWuYP/PMM2H+oQ99KMxnzpwZ5qtWrQpzml/WpnXuuec29OtqkWoMn2QAAABFWTIAAICiLBkAAEBRlgwAAKAoSwYAAFCUdqmKrr766jD/P//n/4T54sWLw/z+++8P86w1I2sb2XvvvcN8yZIlYd7W1hbmS5cuDfP169eHObycq666Ksw//OEPh/ncuXPD/Ac/+EGYP/7442H+L//yL2F+wAEHhPm//du/hXk2JzfddFOYd3d3hzm8nKz9qa+vL8wvuuiiMN+6dWuYb9iwIcz/5//8n2F+0EEHhfn3vve9MJ8wIf53ys2bN4d5T09PmG/atKlSztiVNQFmTZ3Um08yAACAoiwZAABAUZYMAACgKEsGAABQlCUDAAAoqnUo+1P+331ga2ujz9IUJk+eHOb9/f2V8lNPPTXMs5anLVu2hPkhhxwS5rfeemuYZ60lCxYsCPN169aFed2M8DZuOHPyomxOsvtvYGAgzA8//PAwz9rZsvvgqKOOCvNbbrklzLNzzpo1K8yz1py6MSf10tXVFeZZ29qrX/3qML/mmmvC/Bvf+EaYZ22Fu+yyS5j/53/+Z5hn99M999wT5tkcZkbrfq3LnLS0jL9ZyZrS2ttHpwx15513DvOnn366yPWz94gdHR1Frt9ow82KTzIAAICiLBkAAEBRlgwAAKAoSwYAAFCUJQMAAChKu1RFbW1tYT44OBjm2fM2b968MN99993D/MorrwzzrPkga2KYNm1amPf29oZ5nVo2Xk5dzmlOXpTNSdYilT1v2f266667hnnWprNw4cIwz+ZkypQpYZ7NSbMwJ/UyYUL873xZs8y+++4b5m95y1vC/BWveEWYZ61tO+ywQ5hPmjQpzN/0pjeF+Y9+9KMwf/7558O8buoyJy0t429Wuru7wzy7N0vZc889w/yss84K8w984AONPE7T0C4FAABsV5YMAACgKEsGAABQlCUDAAAoypIBAAAUFVerkMracbLmg66urjD/+te/HuavfOUrw/xXv/pVmGctO9lf/GdNFXVq06B5ZPdTNiednZ2V8iuuuCLMDzvssDB/4oknwnzx4sVhnjEPbA9ZK2HWInXiiSeG+Xvf+94wz+Zz48aNYZ7NYTYPZ555Zph/5zvfCXN4SXbvV82zhraqHnnkkTD/53/+5yLXH698kgEAABRlyQAAAIqyZAAAAEVZMgAAgKIsGQAAQFEjbpfq6OgI8/7+/mKHqZO2trYwz5oM1q9fX+Q6mWnTpoX56tWrw/zoo48O84kTJ4Z5d3d3pfMQG29zkt3HWavNhg0bwjx73qrOyezZs8N8zZo1YX744YeH+aRJk8K8r6+v0nmIabl7UXa//vjHPw7z7HmraurUqWGevQ5kLW8rVqwI8/H2c6Sc9vb4bWmpez+TXT+7xxkZn2QAAABFWTIAAICiLBkAAEBRlgwAAKAoSwYAAFDUiNulxmo7zjnnnBPml1xySZhXbbup6tvf/naYn3TSSWGetXhkTQmDg4PbdC5GZqzOybnnnhvmF110UZg3ugnkxhtvDPPTTjstzKu23ZiTxhqr7UN77LFHmD/wwANhnrWqlfKrX/0qzPfaa68wz+Z28uTJYb558+ZtOxjjRva7tOp7qUb/zsia1bKmwcyUKVPCfLzOik8yAACAoiwZAABAUZYMAACgKEsGAABQlCUDAAAoqnVohH+y3+i2mEbLzp+1e2RNAO3tIy7kelnZ0541GWRfd9999w3zxx9/PMx//etfVzpP5kc/+lGYH3nkkZWuU0pd2mqafU4y2f3X09NT6fFVlZqTQw45JMwffPDBMC81Jz/4wQ/C/Oijj650nVLMSRltbW1hnjXLrFu3Lswb3VZYdU7233//MF++fHmYr127Nsy3bt06gtP9xqOPPhrmWVtXo9VlTlpammdWsnNmz2XVfOLEiWHe19c3gtP9RmdnZ5hnzZBV74X58+eH+Zo1aypdp1kM9/z4JAMAACjKkgEAABRlyQAAAIqyZAAAAEVZMgAAgKLKVMA0gapNBi+88EKYZ20gWf71r389zD/wgQ+EedZ2tWzZsjBftGhRmGeNC7Nnzw7zqkarRYrRMTg4GOZPPfVUmE+ePDnMs/v7//7f/xvm73rXu8I8awjJ2qJ22mmnMO/t7Q3zGTNmhHlVo9UixejIWswyWQtTlmevG9dcc02YZy1Sn/rUp8L8da97XZhPnTo1zBcuXBjmVY1WixTlVG1hqvr47Hf1wMBAmGevWX/7t39b6TyNboDLvm6ztIoNxycZAABAUZYMAACgKEsGAABQlCUDAAAoypIBAAAUNW7apTL9/f1hPmfOnDDPmgDa2trCPGs+qNockJ0za9np6uqqdP1Mds6qzRA0t6ypI2s3yzR6TrLrZF83a82Bl5PdZ7fffnuYz5o1K8w3btwY5tn9mr0OVJ2T7PFZq1r2elK1GSdru8q+L5pf9tpRVXZPZY2FmVLnqWqst0hlfJIBAAAUZckAAACKsmQAAABFWTIAAICiLBkAAEBR475dKlO1PalqY0F2/blz54b51VdfHebnn39+mE+fPr3SeTJapCip6v1UdU6+8pWvhPlHPvKRMJ8yZUql8zC+ZK1Kvb29YT558uQwz9qTSjXdZHOStVotWbIkzPfZZ58wP/7444ucR4vU+DNhQpl/y67awlT1taZq02B2L2fNcNnzkL2WPfvss5XOU1XVtqttfS/okwwAAKAoSwYAAFCUJQMAACjKkgEAABRlyQAAAIrSLlVR9pf3VfOsVWTOnDlhfuSRR4b5F7/4xTA/6aSTwvzf//3fwxxKqtpQUfXxWRPIQQcdFObf+MY3wvwd73hHmH/pS18Kc8aXqs04L7zwQkOvn933mzdvDvM//uM/DvO99torzM8666wwnz17dpivXbs2zKG07LUgey9V9bXmuuuuC/MFCxaEedUWqQceeCDM99133zBvtKptXdvaOuWTDAAAoChLBgAAUJQlAwAAKMqSAQAAFGXJAAAAimodGu5Pw196YMW/RG8WVf9iPmsOyBoOsutn7R7Lli0L8yuvvDLMly5dGuZXXXVVmGctIc1uhLdxw43VOamq6pxksmaPrKnj6quvDvOf/vSnYf4v//IvYZ61+DQ7c1LGpEmTwnzatGlh/uyzz4Z51def7Otmv++zlsF3vetdYX7HHXeE+RlnnBHmn/70p8O82dVlTlpamn9WMlmb0ymnnFLpOlWfn6rv7bq7u8M8a5fq6OgI897e3jDfYYcdwrxZaJcCAAC2K0sGAABQlCUDAAAoypIBAAAUZckAAACKah/tA2yrUo0CWUPA1q1bK10nM2XKlDD/4Q9/GOYvvPBCmJ955plh/uijj4b5xo0bR3A6xrqq7TWZbE4GBgaKXD9rzbn77rvDfO3atWH+jne8I8yfeOKJMM+aQxhfskaY7L7M7pvsdaOUrC3qtNNOC/NsTt7ylreEedZu+Pjjjw9/OAhk92aWn3rqqUW+bvbea9999610nVLtT3VqLNuefJIBAAAUZckAAACKsmQAAABFWTIAAICiLBkAAEBRrUMj/JP3qm1OjTZhQrwfDQ4Ohvm8efPCPGtz6u3trXSe9va4qKurqyvMv/71r4f561//+jDP2kz23HPPMF+1alWYj1V1aW5o9jmZNWtWmG/evDnM+/r6Kp0na6nK2n0uu+yyMH/7298e5tncZo0iy5cvD/OxypzEsvsvm5MzzjgjzG+44YYw37RpU6Xz7LLLLmGe3cdLliwJ82yer7vuujCvOldjVV3mpKWlfrPSaNnMVW0IrfraV0p2/ew8zW64WRmb3zUAADBqLBkAAEBRlgwAAKAoSwYAAFCUJQMAACgqrkRqAtlftGctTFn7U9YqkjU6ZHnWKLDbbruF+QknnBDmmc7OzjBfv359peswvmRz0tPTE+bZnGR51eaTbE522mmnMM9afDLZnGzYsKHSdRhftm7dGuYPPvhgmC9cuDDMr7zyyjCv2izz3HPPhfmJJ54Y5jNmzAjz7PtasGBBmI+3Finq57zzzgvziy++uNJ1Gt0ilRmrLVLbyrMBAAAUZckAAACKsmQAAABFWTIAAICiLBkAAEBRrUNZ/czvPrBii0yjjfDYw8oaCP7rv/4rzN/whjeE+T333BPm06ZNC/OqDQQ777xzmK9evbrSdcaqUvfD72u8zcnKlSvD/Nhjjw3zZcuWhfmcOXPCvOqcZK0/q1atqnSdscqcxAYGBsK86v3X398f5t/61rfC/Pzzzw/zn/70p2He1tYW5tl8Zu1SU6ZMCfPs/ONNXeakpaV+swK/bbhZ8UkGAABQlCUDAAAoypIBAAAUZckAAACKsmQAAABFNW27VNba1NvbG+Z9fX1Fvm72dGXPz89//vMwX7x4cZjPnDkzzLP2E15UlzaQus3J9OnTw7ynpyfMR2tOsna2vffeO8xnzJgR5ubk5ZmT2MSJEys9PnudabSsJS1rl1q0aFEDTzN21WVOWlrqNyu8vCOPPDLM77777jDPZrdZaJcCAAC2K0sGAABQlCUDAAAoypIBAAAUZckAAACKqk27VPYX9hdccEGYv//97w/zqVOnhnnWOvNP//RPYf7xj388zLu7uyt93U2bNoV59nzWqdWipI6OjjDv7+8vcv26PG+jNSdXXHFFmL/lLW8J8+x+3bp1a5iff/75Yf6Zz3wmzLOWqq6urjDP2nrG25x0dnaG+ZYtW4pcvy7PW6PnJLuPTzjhhDC/7bbbwry9vT3Mszm85ZZbwvyTn/xkmN97771hfuaZZ4b59ddfH+bZ/NTl511ao38v1Ol50y5FnWmXAgAAtitLBgAAUJQlAwAAKMqSAQAAFGXJAAAAiqpNuxT8PurSBmJOqDNzAsOry5y0tJiVsaJqI1qW1+1+0C4FAABsV5YMAACgKEsGAABQlCUDAAAoypIBAAAU1T7aBwAAgLGqamNZ3VqktpVPMgAAgKIsGQAAQFGWDAAAoChLBgAAUJQlAwAAKMqSAQAAFGXJAAAAirJkAAAARVkyAACAoiwZAABAUZYMAACgqNahoaGh0T4EAAAwdvgkAwAAKMqSAQAAFGXJAAAAirJkAAAARVkyAACAoiwZAABAUZYMAACgKEsGAABQlCUDAAAoypIBAAAUZckAAACKsmQAAABFWTIAAICiLBkAAEBRlgwAAKAoSwYAAFCUJQMAACjKkgEAABRlyQAAAIqyZAAAAEVZMgAAgKIsGQAAQFGWDAAAoChLBgAAUJQlAwAAKMqSAQAAFGXJAAAAirJkAAAARVkyAACAoiwZAABAUZYMAACgKEsGAABQlCUDAAAoqn2kD2xtbW3kOZpG9jwMDQ1t55Pw2+ry/JsT6syc1IvXk3qq0/NvVqiz4WbFJxkAAEBRlgwAAKAoSwYAAFCUJQMAAChqxH/4zYvq9AdhADQvryeMtsHBwTCfMMG/QfP7cxcBAABFWTIAAICiLBkAAEBRlgwAAKAoSwYAAFCUdikAgCZSqhWqbi1S2q7qaeLEidv03/mpAQAARVkyAACAoiwZAABAUZYMAACgKEsGAABQVOvQ0NDQiB7Y2tros8A2G+Ft3HDmhDozJzC8usxJS4tZGU5nZ2eY9/b2VrpOR0dHmA8MDFQ+03gy3Kz4JAMAACjKkgEAABRlyQAAAIqyZAAAAEVZMgAAgKLaR/sA49U+++wT5q997WvDfMmSJWG+YcOGMK9TOwYAjXPggQeG+QknnBDml112WZh7PaHZZC1SEyb4N/Q68FMAAACKsmQAAABFWTIAAICiLBkAAEBRlgwAAKCo1qER1ka0trY2+ixNraenJ8zb2trCvKOjI8z7+/srPT4zZ86cMD/iiCPC/Lvf/W6YT548OczXrVtX6TyNVpf2E3NCnZmT5rBly5YwzxpzsteZrVu3hnl7e7ViyR133DHMjzzyyDC/9dZbw9zrSXXjbVYGBwcrPb5Ui9Qee+wR5o8++miR649Vw82KTzIAAICiLBkAAEBRlgwAAKAoSwYAAFCUJQMAACiqWsUELYsWLQrzrBFhyZIlYf7Xf/3XYZ61SGV/wZ993WOPPTbM3/e+94X59ddfH+aHH354mNetDQSg2ey+++5hPjAwEOZf/epXw/xtb3tbmGctUlVfT4477rgw/8hHPhLmN954Y5gfcsghYe71hJdkbVpXX311Q7+uFqnG8EkGAABQlCUDAAAoypIBAAAUZckAAACKsmQAAABFaZeq6Ctf+UqYf/jDHw7zmTNnhvmdd94Z5o888kiYX3HFFWF+8MEHh3nWQjJhQrxX/sd//EeYd3d3hzm8nL/5m78J84svvjjMs1a1RsvmAbaH7Pd61gI4ZcqUML/lllvC/OGHHw7zrKnniCOOCPN/+7d/C/Oqrye9vb1hDi/Jms/OPPPM7XwSSvAKCwAAFGXJAAAAirJkAAAARVkyAACAoiwZAABAUa1D2Z/y/+4DW1sbfZamsMMOO4R5X19fmA8MDIT5QQcdFOYPPfRQpfO89rWvDfOq7R5ZC1aztIGM8DZuuLE6J8uXLw/zxYsXV7pO1een6s81u352nWZpl/r+978f5sccc0yl65iTeunq6grzLVu2hHn2erL33nuHeTa32X3/x3/8x2H+rW99K8yz173p06dXenzd1GVOWlrG36xk93hbW9t2PsmLpk2bFuYbNmwocv2enp4wz3431M1ws9Icr7AAAEDTsGQAAABFWTIAAICiLBkAAEBRlgwAAKAo7VIVZQ0HWSNC9rxNmTIlzBcsWBDm3/nOd8J8l112CfPsnJMnTw7zZmn9yNSlDaRZ5mT9+vVhnjVplPq+qv6cli5dGuZ77rlnmJ988slhvmzZsjDfunVrmHd2do7gdM3HnNRL1vI0ODhY6TpZ6+H8+fPD/Lbbbgvzqq8nVduxmkVd5qSlZfzNStZoOWnSpIZ+3blz54b5KaecEuaXXnppI4/TNLRLAQAA25UlAwAAKMqSAQAAFGXJAAAAirJkAAAARWmXKqSjoyPMs5aaK664IsyPPvroMH/yySfD/OCDDx7B6X4jayHRBlLGWJ2TrO0m+36ztrXPfvazYf6xj31s2w72O7IWnP7+/krXyVp/mp05aQ7t7e1hnr3OXHLJJWF+/PHHh/nTTz8d5occcsgITvcbWeNP1Xmrm7rMSUvL2J2V7DUle+3Ifrc3+nf1rFmzwnzdunUN/brNQrsUAACwXVkyAACAoiwZAABAUZYMAACgKEsGAABQVFxhEchaLZq9RSKTNRlkTQ+bNm0K8+x5q9oYMXv27DB/7rnnwjxrncraQJq9XWq8uPTSS8P8Pe95T6XrVG2F6unpCfOurq4wz9pxGi07f9aAsXbt2jA/4YQTwvy2227btoPx33g9eVHV15OsrbDq68m8efPC/Ne//nWY77///mE+VtulGD2l3jOVokXq9+OTDAAAoChLBgAAUJQlAwAAKMqSAQAAFGXJAAAAimodympXfveBo/SX/Y12zjnnhHnW4tPo5+HGG28M89NOOy3MR/jj+/8GBwcrn6kZVH0eGqVZ5qS3tzfMn3rqqTA/6qijwnz16tXFzlTCHXfcEebHHHNMmG/cuDHMp0+fXupItWJOGutd73pXmF9++eVh3ujn4YYbbgjz008/Pcyz+6Nq3uzq9H01+6xk7zkmTKjXv3GvX78+zKu+FsyZMyfMsybDZjfcrNTrpwwAADQ9SwYAAFCUJQMAACjKkgEAABRlyQAAAIoa9+1SbW1tYZ6177S3txf5utnTPnHixEpf95BDDgnzBx98MMzXrVtX6TyZu+66K8yPOOKIStcppS5tIM0yJ9k56/I8bqtsHpYtWxbmK1asCPPFixeXOlKt1OXn2yxzUlXWmNPX1xfmo/V6kr3uHXbYYWH+85//PMyff/75EZxuePfcc0+YH3rooUWuX1Vd5qSlpXlmpeprStWmy46OjjDv7++vdJ1sJrZs2RLmVe+F3XffPcyXL19e6TrNQrsUAACwXVkyAACAoiwZAABAUZYMAACgKEsGAABQ1Lhvl8q+r1/+8pdhPmPGjDDv7OwM89tuuy3MzzzzzDDPfhyPPPJImM+bNy/MszaTqVOnhnmzq0sbyGjNyQ477BDm3d3dYf7Rj340zD/96U8XO9NoyBpLsrxUu0+zGO9z0mjZ93X//feH+c477xzm2evJHXfcEeZvfvObwzy77x9//PEwnz17dphnDT7Z751mV5c5aWkZu7NStV0q+5ls3bq10uM/85nPhPn//t//O8yzxrhSsnM2y89duxQAALBdWTIAAICiLBkAAEBRlgwAAKAoSwYAAFDUuG+XKiVrIMgaFKo+nytXrgzz+fPnVzpPo5sSRktd2kDqNidtbW1hPjAwsJ1P8vKy5y37uU6ZMiXMN2zYEOZ1u+9nzZoV5uvWrWvo1zUnzaHRryfPPPNMmGftUtn16zZXpdRlTlpamn9WqrZIVVX1Hqx6nlL3eLO3SGW0SwEAANuVJQMAACjKkgEAABRlyQAAAIqyZAAAAEW1j/YBxoqqbRTZ47N2jyVLloT5Bz7wgTDv6uqqdB7GpqxFqqOjI8z7+/sbeZxU1fnJWqSaxX777Rfmt99++3Y+CXVU6vUkazHLXk/e+973hvnEiRMrnQdeUqqdKWtKzFSdoenTp1d6fF9fX5hnr63Z87DTTjuFedYAV0rVtqttbVzzSQYAAFCUJQMAACjKkgEAABRlyQAAAIqyZAAAAEW1Do3wT8azvzgfb0o9D9nTvnjx4jC/7LLLwjxrOLjzzjvD/POf//wITtd8trX5oDRzsn0MDg4WuU6p5pNmYU7qpdGvJwsXLgzzq666Kszb2+PCybvvvjvM/+7v/m4Ep2s+dZmTlhazMpyqrwXZ85k1rs2ZMyfM/+RP/iTMs9eUFStWhPmiRYvCvFkMNyvj6xUWAABoOEsGAABQlCUDAAAoypIBAAAUZckAAACK0i5VUdYcULXhYN68eWH+8MMPh3nWfPDQQw+F+T/+4z+G+Q477DCC0zWfurSBmJPRlc3hd7/73TDv7u4O85NPPrnYmerEnNRLqdeTWbNmhfljjz0W5tdee22YP/PMM2H+yU9+MswnTZo0gtM1n7rMSUvL2J2Vr33ta2F+6qmnVrpO1ecn+9lms5i9RmSP7+zsDPOsCbSrqyvMm4V2KQAAYLuyZAAAAEVZMgAAgKIsGQAAQFGWDAAAoKj20T7AtsoaBaq2QlRt96h6/YkTJ4b5PffcE+bPPvtsmP/VX/1VmJ9//vlh3tvbO4LTwfaVNW9s2bKl0nVmzJhR6fEnnnhipcc32k033RTmJ5100nY9By9qlteTjo6OMF+2bFmYP/3002H+zne+M8w/85nPhHnV+YSXnHnmmWF++umnh/lpp51W5OtOmzYtzP/oj/6o0nVKNXLWqbFse/JJBgAAUJQlAwAAKMqSAQAAFGXJAAAAirJkAAAARbUOjfBP3rP2jdFStcVj5syZYd7d3R3mfX19Rc7T3h4XeF100UVhftZZZ1U6zz777BPmy5cvD/Oxqi7NDXWbk7Eqa2Hr6uoK86lTpzbyOE3DnMSqvp7MmjUrzDdv3hzmpV5P2trawvyCCy4I8w996ENhnrVFHXDAAWH+i1/8IszHqrrMSUtL/Wal0ao2sWUzkeUDAwPbdrARys6fzXSzG25WxuZ3DQAAjBpLBgAAUJQlAwAAKMqSAQAAFGXJAAAAimradqnsPL29vWFetYGg6vebPX7BggVhvmLFikrnyX5M2fVXr14d5mNVXdpA6jYnzW7y5MlhvnHjxjDPmj2ylrfxxpzEsvNkLUxZU0yWl3o9mTdvXpg/+eSTYV719WTx4sVhnr1ejVV1mZOWlvrNSqO99a1vDfMlS5Zs55MwEtqlAACA7cqSAQAAFGXJAAAAirJkAAAARVkyAACAopq2XapU+0N2nVWrVoX5UUcdFeY//vGPw3zu3LlhnrWQZBYuXBjm2TnHm7q0gdRtTprds88+G+aPPPJImB9zzDGNPE7TMyexRr+ePPPMM2F+8MEHh/myZcvCfP78+WGetUhldttttzBfuXJlpeuMVXWZk5aW+s0K/DbtUgAAwHZlyQAAAIqyZAAAAEVZMgAAgKIsGQAAQFFN2y41ffr0MO/p6Qnzvr6+Il83e7qy5ydrnXrVq14V5jNmzAjzgYGB4Q83jtWlDaRuc9LsBgcHKz2+amvbeGNOYtnrSfa6kb3OVFX19eSHP/xhmL/mNa8Jc68n26Yuc9LSUr9Z4eXtueeeYf7YY4+FedXXuLrRLgUAAGxXlgwAAKAoSwYAAFCUJQMAACjKkgEAABRVm3ap7C/sv/GNb4T5G97whjDv6uoK86xN45Of/GSYf/aznw3zLVu2hPmkSZPCvFSrVbPr7OwM8+z5rKoubSCj1QSSzU+zty1lP9fu7u4wv/zyy8P8b//2b4udqZmNlznJvs///M//DPMjjzwyzLPf69m8feITnwjz7PWkv78/zCdOnBjmpX5fNrvs+Wl0i+Ro0C5FnWmXAgAAtitLBgAAUJQlAwAAKMqSAQAAFGXJAAAAiqpNuxT8PurSBmJOtk2pn5/n/+WZExheXeakpcWsjBXZzzG717K8bveDdikAAGC7smQAAABFWTIAAICiLBkAAEBRlgwAAKCo9tE+AEDWmDEwMBDmbW1tjTwOABRTtbGsbi1S28onGQAAQFGWDAAAoChLBgAAUJQlAwAAKMqSAQAAFKVdCqgtLVIA0Jx8kgEAABRlyQAAAIqyZAAAAEVZMgAAgKIsGQAAQFGtQ0NDQ6N9CAAAYOzwSQYAAFCUJQMAACjKkgEAABRlyQAAAIqyZAAAAEVZMgAAgKIsGQAAQFGWDAAAoChLBgAAUNT/A/+f3qxcPV9MAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_gen.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    new_noise = torch.randn(16, 100, device=device)\n",
    "    result = model_gen(new_noise).clone().detach().cpu()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for ii in range(16):\n",
    "    plt.subplot(4,4,ii+1)\n",
    "    plt.imshow(to_pil_image(0.5*result[ii]+0.5),cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
